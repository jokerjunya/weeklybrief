#!/usr/bin/env python3
"""
ãƒ†ã‚¹ãƒˆç”¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å®Ÿéš›ã®APIãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦Markdownãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ
"""

import json
import os
import sys
from datetime import datetime, timedelta

# data_processing.pyã‹ã‚‰å¿…è¦ãªé–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
exec(open('scripts/data-processing.py').read())

def generate_test_report():
    """ãƒ†ã‚¹ãƒˆç”¨é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    
    print("ğŸš€ ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹")
    print("=" * 50)
    
    # ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
    processor = WeeklyReportProcessor()
    
    # 1. å£²ä¸Šãƒ‡ãƒ¼ã‚¿å‡¦ç†
    print("ğŸ“Š å£²ä¸Šãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸­...")
    sales_data = processor.process_sales_data("/Users/01062544/Downloads/weekly_sales_report.csv")
    print(f"   âœ… ç·å£²ä¸Š: Â¥{sales_data['total_current_sales']:,}")
    
    # 2. æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—
    print("ğŸ“ˆ æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
    stock_tickers = processor.config["data_sources"]["stock_data"]["tickers"]
    stock_data = processor.fetch_stock_data(stock_tickers)
    
    # ã‚¨ãƒ©ãƒ¼ã®ãªã„æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
    valid_stocks = {k: v for k, v in stock_data.items() if "error" not in v}
    print(f"   âœ… å–å¾—æˆåŠŸ: {len(valid_stocks)}/{len(stock_tickers)} éŠ˜æŸ„")
    
    # 3. ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å–å¾—
    print("ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
    keywords = processor.config["data_sources"]["news_data"]["keywords"]
    news_data = processor.fetch_news_data(keywords)
    print(f"   âœ… è¨˜äº‹å–å¾—: {len(news_data)}ä»¶")
    
    # 4. HTMLãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆ
    print("ğŸ”§ HTMLãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆä¸­...")
    tables = processor.generate_html_tables(sales_data, valid_stocks)
    
    # 5. ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰
    sample_schedule = [
        {"subject": "æœˆæ›œå®šä¾‹ä¼šè­°", "start": "2024-01-15T09:00:00Z"},
        {"subject": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¬ãƒ“ãƒ¥ãƒ¼", "start": "2024-01-17T14:00:00Z"},
        {"subject": "é€±æ¬¡å£²ä¸Šãƒ¬ãƒãƒ¼ãƒˆç¢ºèª", "start": "2024-01-19T10:00:00Z"}
    ]
    
    # 6. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report_date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    generation_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒªã‚¹ãƒˆã‚’Markdownå½¢å¼ã«å¤‰æ›
    news_markdown = generate_news_markdown(news_data)
    
    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’Markdownå½¢å¼ã«å¤‰æ›
    schedule_markdown = generate_schedule_markdown(sample_schedule)
    
    # ãƒ¬ãƒãƒ¼ãƒˆå†…å®¹ç”Ÿæˆ
    report_content = f"""# é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ - {report_date}

## ğŸ“Š ä»Šé€±ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆ

- **ç·å£²ä¸Š**: Â¥{sales_data['total_current_sales']:,}
- **å‰å¹´åŒæœŸæ¯”**: {sales_data['yoy_growth_rate']:+.1f}%
- **å‰é€±æ¯”**: {sales_data['weekly_change']:+.1f}%
- **ç›£è¦–éŠ˜æŸ„**: {len(valid_stocks)}éŠ˜æŸ„
- **æ¥­ç•Œãƒ‹ãƒ¥ãƒ¼ã‚¹**: {len(news_data)}ä»¶

---

## ğŸ’° å£²ä¸Šã‚µãƒãƒªãƒ¼

### å…¨ä½“å®Ÿç¸¾
| é …ç›® | å€¤ |
|------|------|
| ä»Šé€±ç·å£²ä¸Š | Â¥{sales_data['total_current_sales']:,} |
| å‰å¹´åŒé€±å£²ä¸Š | Â¥{sales_data['total_previous_year_sales']:,} |
| å‰å¹´åŒæœŸæ¯” | {sales_data['yoy_growth_rate']:+.1f}% |
| å‰é€±æ¯” | {sales_data['weekly_change']:+.1f}% |

### ã‚µãƒ¼ãƒ“ã‚¹åˆ¥å®Ÿç¸¾
| ã‚µãƒ¼ãƒ“ã‚¹å | ä»Šé€±å£²ä¸Š | å‰å¹´åŒæœŸæ¯” | å‰é€±æ¯” |
|------------|----------|------------|--------|"""

    # ã‚µãƒ¼ãƒ“ã‚¹åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    for service in sales_data['services']:
        yoy_icon = "ğŸ“ˆ" if service['yoy_change'] > 0 else "ğŸ“‰"
        weekly_icon = "â¬†ï¸" if service['weekly_change'] > 0 else "â¬‡ï¸"
        
        report_content += f"""
| {service['name']} | Â¥{service['current_sales']:,} | {yoy_icon} {service['yoy_change']:+.1f}% | {weekly_icon} {service['weekly_change']:+.1f}% |"""

    report_content += f"""

---

## ğŸ“ˆ æ ªä¾¡æƒ…å ±

| éŠ˜æŸ„ | ç¾åœ¨ä¾¡æ ¼ | å‰æ—¥å·® | å‰æ—¥æ¯” |
|------|----------|--------|--------|"""

    # æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    ticker_names = processor.config["data_sources"]["stock_data"]["ticker_names"]
    for ticker, data in valid_stocks.items():
        name = ticker_names.get(ticker, ticker)
        change_icon = "â¬†ï¸" if data['change'] > 0 else "â¬‡ï¸" if data['change'] < 0 else "â¡ï¸"
        
        report_content += f"""
| {name} ({ticker}) | ${data['current_price']:.2f} | {change_icon} ${data['change']:+.2f} | {data['change_percent']:+.2f}% |"""

    report_content += f"""

---

## ğŸ“° æ¥­ç•Œãƒ‹ãƒ¥ãƒ¼ã‚¹

{news_markdown}

---

## ğŸ“… ä»Šé€±ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«

{schedule_markdown}

---

## ğŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆæƒ…å ±

- **ç”Ÿæˆæ—¥æ™‚**: {generation_time}
- **ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: 
  - å£²ä¸Šãƒ‡ãƒ¼ã‚¿ï¼ˆCSVï¼‰
  - Alpha Vantage APIï¼ˆæ ªä¾¡ï¼‰
  - NewsAPIï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼‰
  - Outlookï¼ˆã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼‰

---

*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ*
"""

    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ_ãƒ†ã‚¹ãƒˆ_{timestamp}.md"
    filepath = os.path.join("reports", filename)
    
    # reportsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    os.makedirs("reports", exist_ok=True)
    
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {filepath}")
    
    # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
    print("\nğŸ“Š ç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆçµ±è¨ˆ:")
    print(f"   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {len(report_content):,} æ–‡å­—")
    print(f"   å£²ä¸Šãƒ‡ãƒ¼ã‚¿: {len(sales_data['services'])} ã‚µãƒ¼ãƒ“ã‚¹")
    print(f"   æ ªä¾¡ãƒ‡ãƒ¼ã‚¿: {len(valid_stocks)} éŠ˜æŸ„")
    print(f"   ãƒ‹ãƒ¥ãƒ¼ã‚¹: {len(news_data)} è¨˜äº‹")
    print(f"   ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«: {len(sample_schedule)} äºˆå®š")
    
    return filepath

def generate_news_markdown(news_data):
    """ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’Markdownå½¢å¼ã«å¤‰æ›"""
    if not news_data:
        return "ä»Šé€±ã¯é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
    
    markdown = ""
    current_keyword = None
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    news_by_keyword = {}
    for article in news_data:
        keyword = article.get('keyword', 'ãã®ä»–')
        if keyword not in news_by_keyword:
            news_by_keyword[keyword] = []
        news_by_keyword[keyword].append(article)
    
    for keyword, articles in news_by_keyword.items():
        markdown += f"\n### ğŸ” {keyword} é–¢é€£\n\n"
        
        for i, article in enumerate(articles[:3], 1):  # å„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æœ€å¤§3ä»¶
            # æ—¥ä»˜ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            pub_date = datetime.fromisoformat(article['published_at'].replace('Z', '+00:00'))
            date_str = pub_date.strftime("%m/%d %H:%M")
            
            markdown += f"{i}. **[{article['title']}]({article['url']})**\n"
            
            # æ—¥æœ¬èªè¦ç´„ã‚’å„ªå…ˆè¡¨ç¤ºã€ãªã‘ã‚Œã°å…ƒã®èª¬æ˜æ–‡
            if article.get('summary_jp'):
                markdown += f"   ğŸ‡¯ğŸ‡µ **è¦ç´„**: {article['summary_jp']}\n"
            elif article.get('description'):
                description = article['description'][:100] + "..." if len(article['description']) > 100 else article['description']
                markdown += f"   ğŸ“ {description}\n"
            
            markdown += f"   *{date_str}*\n\n"
    
    return markdown

def generate_schedule_markdown(schedule_data):
    """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’Markdownå½¢å¼ã«å¤‰æ›"""
    if not schedule_data:
        return "ä»Šé€±ã¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
    
    markdown = ""
    for item in schedule_data:
        # æ—¥ä»˜ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        start_time = datetime.fromisoformat(item['start'].replace('Z', '+00:00'))
        date_str = start_time.strftime("%m/%d (%a) %H:%M")
        
        markdown += f"- **{item['subject']}**\n"
        markdown += f"  ğŸ“… {date_str}\n\n"
    
    return markdown

if __name__ == "__main__":
    try:
        report_path = generate_test_report()
        
        print("\nğŸ‰ ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”ŸæˆæˆåŠŸï¼")
        print(f"ğŸ“ ä¿å­˜å ´æ‰€: {report_path}")
        print("\nğŸ“– ãƒ¬ãƒãƒ¼ãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
        print(f"   open {report_path}")
        print("\nğŸ”„ æ¬¡å›å®Ÿè¡Œæ™‚ã¯æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã§æ›´æ–°ã•ã‚Œã¾ã™")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc() 