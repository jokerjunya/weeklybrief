#!/usr/bin/env python3
"""
é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Power Automateã‹ã‚‰å‘¼ã³å‡ºã—å¯èƒ½ãªå½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
"""

import json
import os
import pandas as pd
from datetime import datetime, timedelta
import requests
from typing import Dict, List, Any
from news_summarizer import NewsSummarizer
from local_llm_summarizer import LocalLLMSummarizer

class WeeklyReportProcessor:
    def __init__(self, config_path: str = "config/settings.json"):
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
        # ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦ç´„æ©Ÿèƒ½ã‚’åˆæœŸåŒ–ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«LLMå„ªå…ˆï¼‰
        local_llm_config = self.config["data_sources"].get("local_llm", {})
        if local_llm_config.get("enabled", False):
            self.news_summarizer = LocalLLMSummarizer(config_path)
            print("ğŸ“± ãƒ­ãƒ¼ã‚«ãƒ«LLMï¼ˆQwen3ï¼‰è¦ç´„æ©Ÿèƒ½ã‚’ä½¿ç”¨")
        else:
            self.news_summarizer = NewsSummarizer(config_path)
            print("â˜ï¸  ã‚¯ãƒ©ã‚¦ãƒ‰APIè¦ç´„æ©Ÿèƒ½ã‚’ä½¿ç”¨")
    
    def process_sales_data(self, csv_file_path: str = None) -> Dict[str, Any]:
        """
        å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ï¼ˆPlacement: ãƒ€ãƒŸãƒ¼ã€Online Platform: å®Ÿãƒ‡ãƒ¼ã‚¿ï¼‰
        """
        # Online Platformï¼ˆã‚µãƒ¼ãƒ“ã‚¹Bï¼‰ã®å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹
        online_platform_csv = "/Users/01062544/Downloads/Revenue_jp_weekly_non-RAG_YoY&WoW.csv"
        
        # ã‚µãƒ¼ãƒ“ã‚¹Aï¼ˆPlacementï¼‰ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
        placement_data = {
            "name": "Placement",
            "current_sales": 12345678,
            "yoy_change": 21.9,
            "weekly_change": 3.2
        }
        
        # ã‚µãƒ¼ãƒ“ã‚¹Bï¼ˆOnline Platformï¼‰ã®å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        online_platform_data = self._load_online_platform_data(online_platform_csv)
        
        # çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        services = [placement_data, online_platform_data]
        
        # å…¨ä½“é›†è¨ˆ
        total_current = placement_data["current_sales"] + online_platform_data["current_sales"]
        
        # å‰å¹´åŒæœŸãƒ‡ãƒ¼ã‚¿ï¼ˆæ¦‚ç®—ï¼‰
        placement_prev_year = placement_data["current_sales"] / (1 + placement_data["yoy_change"] / 100)
        online_platform_prev_year = online_platform_data["previous_year_sales"]
        total_previous_year = placement_prev_year + online_platform_prev_year
        
        # å‰é€±ãƒ‡ãƒ¼ã‚¿ï¼ˆæ¦‚ç®—ï¼‰
        placement_prev_week = placement_data["current_sales"] / (1 + placement_data["weekly_change"] / 100)
        online_platform_prev_week = online_platform_data["previous_week_sales"]
        total_previous_week = placement_prev_week + online_platform_prev_week
        
        # å…¨ä½“æˆé•·ç‡è¨ˆç®—
        yoy_growth = ((total_current - total_previous_year) / total_previous_year * 100) if total_previous_year > 0 else 0
        weekly_change = ((total_current - total_previous_week) / total_previous_week * 100) if total_previous_week > 0 else 0
        
        return {
            "total_current_sales": int(total_current),
            "total_previous_year_sales": int(total_previous_year),
            "yoy_growth_rate": round(yoy_growth, 1),
            "weekly_change": round(weekly_change, 1),
            "service_count": len(services),
            "services": services
        }
    
    def _load_online_platform_data(self, csv_path: str) -> Dict[str, Any]:
        """
        Online Platformï¼ˆã‚µãƒ¼ãƒ“ã‚¹Bï¼‰ã®å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        """
        try:
            if not os.path.exists(csv_path):
                print(f"âš ï¸  Online Platformãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
                return self._get_dummy_online_platform_data()
            
            df = pd.read_csv(csv_path)
            
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹é€ : this_week_revenue_jpy,last_week_revenue_jpy,last_year_same_week_revenue_jpy,wow_pct,yoy_pct
            row = df.iloc[0]  # æœ€åˆã®è¡Œã‚’å–å¾—
            
            current_sales = int(row['this_week_revenue_jpy'])
            previous_week_sales = int(row['last_week_revenue_jpy'])
            previous_year_sales = int(row['last_year_same_week_revenue_jpy'])
            wow_pct = float(row['wow_pct'])
            yoy_pct = float(row['yoy_pct'])
            
            return {
                "name": "Online Platform",
                "current_sales": current_sales,
                "previous_week_sales": previous_week_sales,
                "previous_year_sales": previous_year_sales,
                "yoy_change": yoy_pct,
                "weekly_change": wow_pct
            }
            
        except Exception as e:
            print(f"âŒ Online Platformãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return self._get_dummy_online_platform_data()
    
    def _get_dummy_online_platform_data(self) -> Dict[str, Any]:
        """
        Online Platformã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
        """
        return {
            "name": "Online Platform",
            "current_sales": 8765432,
            "previous_week_sales": 8987654,
            "previous_year_sales": 9876543,
            "yoy_change": -11.2,
            "weekly_change": -2.5
        }
    
    def fetch_stock_data(self, tickers: List[str]) -> Dict[str, Any]:
        """
        æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ãƒ»å‡¦ç†
        """
        api_key = self.config["data_sources"]["stock_data"]["api_key"]
        stock_data = {}
        
        for ticker in tickers:
            try:
                url = f"https://www.alphavantage.co/query"
                params = {
                    "function": "TIME_SERIES_DAILY",
                    "symbol": ticker,
                    "apikey": api_key
                }
                response = requests.get(url, params=params)
                data = response.json()
                
                # æœ€æ–°ã®æ ªä¾¡æƒ…å ±ã‚’æŠ½å‡º
                if "Time Series (Daily)" in data:
                    time_series = data["Time Series (Daily)"]
                    dates = list(time_series.keys())
                    if dates:
                        latest_date = dates[0]
                        latest_data = time_series[latest_date]
                        previous_date = dates[1] if len(dates) > 1 else dates[0]
                        previous_data = time_series[previous_date]
                        
                        current_price = float(latest_data["4. close"])
                        previous_price = float(previous_data["4. close"])
                        change = current_price - previous_price
                        change_percent = (change / previous_price) * 100
                        
                        stock_data[ticker] = {
                            "current_price": current_price,
                            "change": round(change, 2),
                            "change_percent": round(change_percent, 2)
                        }
                    else:
                        stock_data[ticker] = {"error": "No data available"}
                else:
                    stock_data[ticker] = {"error": f"Unexpected response format: {list(data.keys())}"}
                                         
            except Exception as e:
                print(f"Error processing {ticker}: {e}")
                stock_data[ticker] = {"error": str(e)}
        
        return stock_data
    
    def fetch_news_data(self, keywords: List[str]) -> List[Dict[str, Any]]:
        """
        ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ãƒ»å‡¦ç†ï¼ˆéå»1é€±é–“ä»¥å†…ï¼‰
        """
        api_key = self.config["data_sources"]["news_data"]["api_key"]
        all_articles = []
        
        # éå»1é€±é–“ã®æ—¥ä»˜ã‚’è¨ˆç®—
        from datetime import datetime, timedelta
        one_week_ago = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
        
        for keyword in keywords:
            try:
                url = "https://newsapi.org/v2/everything"
                params = {
                    "q": keyword,
                    "apiKey": api_key,
                    "language": "en",
                    "sortBy": "publishedAt",
                    "pageSize": 5,
                    "from": one_week_ago  # éå»1é€±é–“ä»¥å†…ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã¿
                }
                response = requests.get(url, params=params)
                data = response.json()
                
                if data.get("articles"):
                    for article in data["articles"]:
                        # ã‚ˆã‚Šå¤šãã®æƒ…å ±ã‚’åé›†ï¼ˆtitle + description + contentï¼‰
                        title = article.get("title", "")
                        description = article.get("description", "") or ""
                        content = article.get("content", "") or ""
                        
                        # contentã‹ã‚‰HTMLã‚¿ã‚°ã‚„ãƒã‚¤ã‚ºã‚’é™¤å»
                        import re
                        if content:
                            # ä¸€èˆ¬çš„ãªãƒã‚¤ã‚ºãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤å»
                            content = re.sub(r'[{}\[\]"\'\\]', '', content)
                            content = re.sub(r'window\.open.*?return false;', '', content)
                            content = re.sub(r'https?://[^\s]+', '', content)  # URLã‚’é™¤å»
                            content = re.sub(r'\s+', ' ', content).strip()  # ç©ºç™½ã‚’æ­£è¦åŒ–
                        
                        all_articles.append({
                            "title": title,
                            "description": description,
                            "content": content,  # æ–°è¦è¿½åŠ 
                            "url": article["url"],
                            "published_at": article["publishedAt"],
                            "keyword": keyword
                        })
            except Exception as e:
                print(f"Error fetching news for {keyword}: {e}")
        
        # æ—¥ä»˜é †ã§ã‚½ãƒ¼ãƒˆã—ã€ä¸Šä½10ä»¶ã‚’å–å¾—
        all_articles.sort(key=lambda x: x["published_at"], reverse=True)
        selected_articles = all_articles[:10]
        
        # æ—¥æœ¬èªè¦ç´„ã‚’è¿½åŠ 
        processed_articles = self.news_summarizer.process_news_articles(selected_articles)
        
        return processed_articles
    
    def get_weekly_news_summary(self, articles: List[Dict[str, Any]]) -> str:
        """
        é€±é–“ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ
        
        Args:
            articles (List[Dict]): å‡¦ç†æ¸ˆã¿ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ãƒªã‚¹ãƒˆ
        
        Returns:
            str: é€±é–“ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚µãƒãƒªãƒ¼ï¼ˆ300æ–‡å­—ç¨‹åº¦ï¼‰
        """
        return self.news_summarizer.generate_weekly_news_summary(articles)
    
    def format_schedule_data(self, outlook_events: List[Dict]) -> str:
        """
        Outlookã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ•´å½¢
        """
        if not outlook_events:
            return "ä»Šé€±ã¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
        
        formatted_schedule = []
        for event in outlook_events:
            # TODO: å®Ÿéš›ã®Outlookã‚¤ãƒ™ãƒ³ãƒˆæ§‹é€ ã«å¿œã˜ã¦å®Ÿè£…
            formatted_schedule.append(f"â€¢ {event.get('subject', 'ã‚¿ã‚¤ãƒˆãƒ«æœªè¨­å®š')}")
        
        return "\n".join(formatted_schedule)
    
    def generate_html_tables(self, sales_data: Dict, stock_data: Dict) -> Dict[str, str]:
        """
        HTMLãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç”Ÿæˆ
        """
        # å£²ä¸Šã‚µãƒãƒªãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«
        sales_summary_html = f"""
        <table border="1" style="border-collapse: collapse; width: 100%;">
            <tr style="background-color: #f2f2f2;"><th>é …ç›®</th><th>å€¤</th></tr>
            <tr><td>ä»Šé€±ç·å£²ä¸Š</td><td>Â¥{sales_data.get('total_current_sales', 0):,}</td></tr>
            <tr><td>å‰å¹´åŒé€±å£²ä¸Š</td><td>Â¥{sales_data.get('total_previous_year_sales', 0):,}</td></tr>
            <tr><td>å‰å¹´åŒæœŸæ¯”</td><td>{sales_data.get('yoy_growth_rate', 0)}%</td></tr>
            <tr><td>å‰é€±æ¯”</td><td>{sales_data.get('weekly_change', 0)}%</td></tr>
        </table>
        """
        
        # ã‚µãƒ¼ãƒ“ã‚¹åˆ¥å£²ä¸Šãƒ†ãƒ¼ãƒ–ãƒ«
        if sales_data.get("services"):
            service_rows = []
            for service in sales_data["services"]:
                yoy_color = "green" if service.get('yoy_change', 0) > 0 else "red"
                weekly_color = "green" if service.get('weekly_change', 0) > 0 else "red"
                service_rows.append(f"""
                    <tr>
                        <td>{service['name']}</td>
                        <td>Â¥{service['current_sales']:,}</td>
                        <td style="color: {yoy_color};">{service['yoy_change']}%</td>
                        <td style="color: {weekly_color};">{service['weekly_change']}%</td>
                    </tr>
                """)
            
            services_html = f"""
            <table border="1" style="border-collapse: collapse; width: 100%; margin-top: 10px;">
                <tr style="background-color: #f2f2f2;"><th>ã‚µãƒ¼ãƒ“ã‚¹å</th><th>ä»Šé€±å£²ä¸Š</th><th>å‰å¹´åŒæœŸæ¯”</th><th>å‰é€±æ¯”</th></tr>
                {''.join(service_rows)}
            </table>
            """
            sales_table_html = sales_summary_html + services_html
        else:
            sales_table_html = sales_summary_html
        
        # æ ªä¾¡ãƒ†ãƒ¼ãƒ–ãƒ«
        stock_rows = []
        ticker_names = self.config["data_sources"]["stock_data"]["ticker_names"]
        
        for ticker, data in stock_data.items():
            if "error" not in data:
                name = ticker_names.get(ticker, ticker)
                change_color = "green" if data.get('change_percent', 0) > 0 else "red"
                stock_rows.append(f"""
                    <tr>
                        <td>{name} ({ticker})</td>
                        <td>{data.get('current_price', 'N/A')}</td>
                        <td style="color: {change_color};">{data.get('change', 'N/A')}</td>
                        <td style="color: {change_color};">{data.get('change_percent', 'N/A')}%</td>
                    </tr>
                """)
        
        stock_html = f"""
        <table border="1" style="border-collapse: collapse; width: 100%;">
            <tr style="background-color: #f2f2f2;"><th>éŠ˜æŸ„</th><th>ç¾åœ¨ä¾¡æ ¼</th><th>å‰æ—¥å·®</th><th>å‰æ—¥æ¯”</th></tr>
            {''.join(stock_rows)}
        </table>
        """
        
        return {
            "sales_table": sales_table_html,
            "stock_table": stock_html
        }

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œç”¨
    processor = WeeklyReportProcessor()
    
    # å£²ä¸Šãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆï¼ˆãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ–¹å¼ï¼‰
    print("=== å£²ä¸Šãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆ ===")
    print("ğŸ“Š Placementï¼ˆãƒ€ãƒŸãƒ¼ï¼‰+ Online Platformï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ï¼‰ã®çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ")
    sales_data = processor.process_sales_data()
    print(json.dumps(sales_data, indent=2, ensure_ascii=False))
    
    # ã‚µãƒ³ãƒ—ãƒ«æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆï¼ˆå®Ÿéš›ã®APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆï¼‰
    print("\n=== HTMLãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆãƒ†ã‚¹ãƒˆ ===")
    sample_stock_data = {
        "AAPL": {"current_price": 195.64, "change": 2.34, "change_percent": 1.21},
        "GOOGL": {"current_price": 2750.80, "change": -15.20, "change_percent": -0.55},
        "MSFT": {"current_price": 378.91, "change": 5.67, "change_percent": 1.52}
    }
    
    tables = processor.generate_html_tables(sales_data, sample_stock_data)
    print("å£²ä¸Šãƒ†ãƒ¼ãƒ–ãƒ«:")
    print(tables["sales_table"])
    print("\næ ªä¾¡ãƒ†ãƒ¼ãƒ–ãƒ«:")
    print(tables["stock_table"])
    
    # ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆï¼ˆAPIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ï¼‰
    if processor.config["data_sources"]["news_data"]["api_key"] != "API_KEY_TO_BE_PROVIDED":
        print("\n=== ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆ ===")
        sample_keywords = ["OpenAI", "Anthropic"]
        news_data = processor.fetch_news_data(sample_keywords)
        print(f"å–å¾—è¨˜äº‹æ•°: {len(news_data)}")
    else:
        print("\n=== ãƒ‹ãƒ¥ãƒ¼ã‚¹APIã‚­ãƒ¼ãŒæœªè¨­å®šã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ— ===")
    
    if processor.config["data_sources"]["stock_data"]["api_key"] != "API_KEY_TO_BE_PROVIDED":
        print("\n=== æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆ ===")
        tickers = processor.config["data_sources"]["stock_data"]["tickers"]
        stock_data = processor.fetch_stock_data(tickers)
        print(json.dumps(stock_data, indent=2))
    else:
        print("\n=== æ ªä¾¡APIã‚­ãƒ¼ãŒæœªè¨­å®šã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ— ===") 