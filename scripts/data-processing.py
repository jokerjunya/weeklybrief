#!/usr/bin/env python3
"""
é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Power Automateã‹ã‚‰å‘¼ã³å‡ºã—å¯èƒ½ãªå½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
"""

import json
import pandas as pd
from datetime import datetime, timedelta
import requests
from typing import Dict, List, Any
from news_summarizer import NewsSummarizer
from local_llm_summarizer import LocalLLMSummarizer

class WeeklyReportProcessor:
    def __init__(self, config_path: str = "config/settings.json"):
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
        # ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦ç´„æ©Ÿèƒ½ã‚’åˆæœŸåŒ–ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«LLMå„ªå…ˆï¼‰
        local_llm_config = self.config["data_sources"].get("local_llm", {})
        if local_llm_config.get("enabled", False):
            self.news_summarizer = LocalLLMSummarizer(config_path)
            print("ğŸ“± ãƒ­ãƒ¼ã‚«ãƒ«LLMï¼ˆQwen3ï¼‰è¦ç´„æ©Ÿèƒ½ã‚’ä½¿ç”¨")
        else:
            self.news_summarizer = NewsSummarizer(config_path)
            print("â˜ï¸  ã‚¯ãƒ©ã‚¦ãƒ‰APIè¦ç´„æ©Ÿèƒ½ã‚’ä½¿ç”¨")
    
    def process_sales_data(self, csv_file_path: str) -> Dict[str, Any]:
        """
        å£²ä¸ŠCSVãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã¦ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ
        """
        try:
            df = pd.read_csv(csv_file_path, encoding='utf-8')
            
            # åˆè¨ˆè¡Œã‚’é™¤ã„ã¦ã‚µãƒ¼ãƒ“ã‚¹åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            service_data = df[df['ã‚µãƒ¼ãƒ“ã‚¹å'] != 'åˆè¨ˆï¼å¹³å‡'].copy()
            total_row = df[df['ã‚µãƒ¼ãƒ“ã‚¹å'] == 'åˆè¨ˆï¼å¹³å‡'].iloc[0]
            
            # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ•°å€¤ã‚’æ•´æ•°ã«å¤‰æ›ï¼‰
            def clean_numeric(value):
                if isinstance(value, str):
                    return int(value.replace(',', ''))
                # NumPyå‹ã‚’Pythonæ¨™æº–å‹ã«å¤‰æ›
                if hasattr(value, 'item'):
                    return value.item()
                return int(value) if isinstance(value, (int, float)) else value
            
            # ã‚µãƒãƒªãƒ¼æƒ…å ±ã‚’ç”Ÿæˆ
            summary = {
                "total_current_sales": clean_numeric(total_row['ä»Šé€±å£²ä¸Šé¡ (Â¥)']),
                "total_previous_year_sales": clean_numeric(total_row['å‰å¹´åŒé€±å£²ä¸Šé¡ (Â¥)']),
                "yoy_growth_rate": float(total_row['YoYå¢—æ¸›ç‡ (%)']),
                "weekly_change": float(total_row['å‰é€±æ¯” (%)']),
                "service_count": int(len(service_data)),
                "services": []
            }
            
            # ã‚µãƒ¼ãƒ“ã‚¹åˆ¥è©³ç´°
            for _, row in service_data.iterrows():
                summary["services"].append({
                    "name": str(row['ã‚µãƒ¼ãƒ“ã‚¹å']),
                    "current_sales": clean_numeric(row['ä»Šé€±å£²ä¸Šé¡ (Â¥)']),
                    "yoy_change": float(row['YoYå¢—æ¸›ç‡ (%)']),
                    "weekly_change": float(row['å‰é€±æ¯” (%)'])
                })
            
            return summary
        except Exception as e:
            return {"error": str(e)}
    
    def fetch_stock_data(self, tickers: List[str]) -> Dict[str, Any]:
        """
        æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ãƒ»å‡¦ç†
        """
        api_key = self.config["data_sources"]["stock_data"]["api_key"]
        stock_data = {}
        
        for ticker in tickers:
            try:
                url = f"https://www.alphavantage.co/query"
                params = {
                    "function": "TIME_SERIES_DAILY",
                    "symbol": ticker,
                    "apikey": api_key
                }
                response = requests.get(url, params=params)
                data = response.json()
                
                # æœ€æ–°ã®æ ªä¾¡æƒ…å ±ã‚’æŠ½å‡º
                if "Time Series (Daily)" in data:
                    time_series = data["Time Series (Daily)"]
                    dates = list(time_series.keys())
                    if dates:
                        latest_date = dates[0]
                        latest_data = time_series[latest_date]
                        previous_date = dates[1] if len(dates) > 1 else dates[0]
                        previous_data = time_series[previous_date]
                        
                        current_price = float(latest_data["4. close"])
                        previous_price = float(previous_data["4. close"])
                        change = current_price - previous_price
                        change_percent = (change / previous_price) * 100
                        
                        stock_data[ticker] = {
                            "current_price": current_price,
                            "change": round(change, 2),
                            "change_percent": round(change_percent, 2)
                        }
                    else:
                        stock_data[ticker] = {"error": "No data available"}
                else:
                    stock_data[ticker] = {"error": f"Unexpected response format: {list(data.keys())}"}
                                         
            except Exception as e:
                print(f"Error processing {ticker}: {e}")
                stock_data[ticker] = {"error": str(e)}
        
        return stock_data
    
    def fetch_news_data(self, keywords: List[str]) -> List[Dict[str, Any]]:
        """
        ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ãƒ»å‡¦ç†ï¼ˆéå»1é€±é–“ä»¥å†…ï¼‰
        """
        api_key = self.config["data_sources"]["news_data"]["api_key"]
        all_articles = []
        
        # éå»1é€±é–“ã®æ—¥ä»˜ã‚’è¨ˆç®—
        from datetime import datetime, timedelta
        one_week_ago = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
        
        for keyword in keywords:
            try:
                url = "https://newsapi.org/v2/everything"
                params = {
                    "q": keyword,
                    "apiKey": api_key,
                    "language": "en",
                    "sortBy": "publishedAt",
                    "pageSize": 5,
                    "from": one_week_ago  # éå»1é€±é–“ä»¥å†…ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã¿
                }
                response = requests.get(url, params=params)
                data = response.json()
                
                if data.get("articles"):
                    for article in data["articles"]:
                        all_articles.append({
                            "title": article["title"],
                            "description": article["description"],
                            "url": article["url"],
                            "published_at": article["publishedAt"],
                            "keyword": keyword
                        })
            except Exception as e:
                print(f"Error fetching news for {keyword}: {e}")
        
        # æ—¥ä»˜é †ã§ã‚½ãƒ¼ãƒˆã—ã€ä¸Šä½10ä»¶ã‚’å–å¾—
        all_articles.sort(key=lambda x: x["published_at"], reverse=True)
        selected_articles = all_articles[:10]
        
        # æ—¥æœ¬èªè¦ç´„ã‚’è¿½åŠ 
        processed_articles = self.news_summarizer.process_news_articles(selected_articles)
        
        return processed_articles
    
    def format_schedule_data(self, outlook_events: List[Dict]) -> str:
        """
        Outlookã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ•´å½¢
        """
        if not outlook_events:
            return "ä»Šé€±ã¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
        
        formatted_schedule = []
        for event in outlook_events:
            # TODO: å®Ÿéš›ã®Outlookã‚¤ãƒ™ãƒ³ãƒˆæ§‹é€ ã«å¿œã˜ã¦å®Ÿè£…
            formatted_schedule.append(f"â€¢ {event.get('subject', 'ã‚¿ã‚¤ãƒˆãƒ«æœªè¨­å®š')}")
        
        return "\n".join(formatted_schedule)
    
    def generate_html_tables(self, sales_data: Dict, stock_data: Dict) -> Dict[str, str]:
        """
        HTMLãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç”Ÿæˆ
        """
        # å£²ä¸Šã‚µãƒãƒªãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«
        sales_summary_html = f"""
        <table border="1" style="border-collapse: collapse; width: 100%;">
            <tr style="background-color: #f2f2f2;"><th>é …ç›®</th><th>å€¤</th></tr>
            <tr><td>ä»Šé€±ç·å£²ä¸Š</td><td>Â¥{sales_data.get('total_current_sales', 0):,}</td></tr>
            <tr><td>å‰å¹´åŒé€±å£²ä¸Š</td><td>Â¥{sales_data.get('total_previous_year_sales', 0):,}</td></tr>
            <tr><td>å‰å¹´åŒæœŸæ¯”</td><td>{sales_data.get('yoy_growth_rate', 0)}%</td></tr>
            <tr><td>å‰é€±æ¯”</td><td>{sales_data.get('weekly_change', 0)}%</td></tr>
        </table>
        """
        
        # ã‚µãƒ¼ãƒ“ã‚¹åˆ¥å£²ä¸Šãƒ†ãƒ¼ãƒ–ãƒ«
        if sales_data.get("services"):
            service_rows = []
            for service in sales_data["services"]:
                yoy_color = "green" if service.get('yoy_change', 0) > 0 else "red"
                weekly_color = "green" if service.get('weekly_change', 0) > 0 else "red"
                service_rows.append(f"""
                    <tr>
                        <td>{service['name']}</td>
                        <td>Â¥{service['current_sales']:,}</td>
                        <td style="color: {yoy_color};">{service['yoy_change']}%</td>
                        <td style="color: {weekly_color};">{service['weekly_change']}%</td>
                    </tr>
                """)
            
            services_html = f"""
            <table border="1" style="border-collapse: collapse; width: 100%; margin-top: 10px;">
                <tr style="background-color: #f2f2f2;"><th>ã‚µãƒ¼ãƒ“ã‚¹å</th><th>ä»Šé€±å£²ä¸Š</th><th>å‰å¹´åŒæœŸæ¯”</th><th>å‰é€±æ¯”</th></tr>
                {''.join(service_rows)}
            </table>
            """
            sales_table_html = sales_summary_html + services_html
        else:
            sales_table_html = sales_summary_html
        
        # æ ªä¾¡ãƒ†ãƒ¼ãƒ–ãƒ«
        stock_rows = []
        ticker_names = self.config["data_sources"]["stock_data"]["ticker_names"]
        
        for ticker, data in stock_data.items():
            if "error" not in data:
                name = ticker_names.get(ticker, ticker)
                change_color = "green" if data.get('change_percent', 0) > 0 else "red"
                stock_rows.append(f"""
                    <tr>
                        <td>{name} ({ticker})</td>
                        <td>{data.get('current_price', 'N/A')}</td>
                        <td style="color: {change_color};">{data.get('change', 'N/A')}</td>
                        <td style="color: {change_color};">{data.get('change_percent', 'N/A')}%</td>
                    </tr>
                """)
        
        stock_html = f"""
        <table border="1" style="border-collapse: collapse; width: 100%;">
            <tr style="background-color: #f2f2f2;"><th>éŠ˜æŸ„</th><th>ç¾åœ¨ä¾¡æ ¼</th><th>å‰æ—¥å·®</th><th>å‰æ—¥æ¯”</th></tr>
            {''.join(stock_rows)}
        </table>
        """
        
        return {
            "sales_table": sales_table_html,
            "stock_table": stock_html
        }

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œç”¨
    processor = WeeklyReportProcessor()
    
    # å£²ä¸Šãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆ
    print("=== å£²ä¸Šãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆ ===")
    sales_data = processor.process_sales_data("/Users/01062544/Downloads/weekly_sales_report.csv")
    print(json.dumps(sales_data, indent=2, ensure_ascii=False))
    
    # ã‚µãƒ³ãƒ—ãƒ«æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆï¼ˆå®Ÿéš›ã®APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆï¼‰
    print("\n=== HTMLãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆãƒ†ã‚¹ãƒˆ ===")
    sample_stock_data = {
        "AAPL": {"current_price": 195.64, "change": 2.34, "change_percent": 1.21},
        "GOOGL": {"current_price": 2750.80, "change": -15.20, "change_percent": -0.55},
        "MSFT": {"current_price": 378.91, "change": 5.67, "change_percent": 1.52}
    }
    
    tables = processor.generate_html_tables(sales_data, sample_stock_data)
    print("å£²ä¸Šãƒ†ãƒ¼ãƒ–ãƒ«:")
    print(tables["sales_table"])
    print("\næ ªä¾¡ãƒ†ãƒ¼ãƒ–ãƒ«:")
    print(tables["stock_table"])
    
    # ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆï¼ˆAPIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ï¼‰
    if processor.config["data_sources"]["news_data"]["api_key"] != "API_KEY_TO_BE_PROVIDED":
        print("\n=== ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆ ===")
        sample_keywords = ["OpenAI", "Anthropic"]
        news_data = processor.fetch_news_data(sample_keywords)
        print(f"å–å¾—è¨˜äº‹æ•°: {len(news_data)}")
    else:
        print("\n=== ãƒ‹ãƒ¥ãƒ¼ã‚¹APIã‚­ãƒ¼ãŒæœªè¨­å®šã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ— ===")
    
    if processor.config["data_sources"]["stock_data"]["api_key"] != "API_KEY_TO_BE_PROVIDED":
        print("\n=== æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆ ===")
        tickers = processor.config["data_sources"]["stock_data"]["tickers"]
        stock_data = processor.fetch_stock_data(tickers)
        print(json.dumps(stock_data, indent=2))
    else:
        print("\n=== æ ªä¾¡APIã‚­ãƒ¼ãŒæœªè¨­å®šã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ— ===") 