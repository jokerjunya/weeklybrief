#!/usr/bin/env python3
"""
é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Power Automateã‹ã‚‰å‘¼ã³å‡ºã—å¯èƒ½ãªå½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
"""

import json
import os
import pandas as pd
from datetime import datetime, timedelta
import requests
from typing import Dict, List, Any
from news_summarizer import NewsSummarizer
from local_llm_summarizer import LocalLLMSummarizer

class WeeklyReportProcessor:
    def __init__(self, config_path: str = "config/settings.json"):
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
        # ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦ç´„æ©Ÿèƒ½ã‚’åˆæœŸåŒ–ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«LLMå„ªå…ˆï¼‰
        local_llm_config = self.config["data_sources"].get("local_llm", {})
        if local_llm_config.get("enabled", False):
            self.news_summarizer = LocalLLMSummarizer(config_path)
            print("ğŸ“± ãƒ­ãƒ¼ã‚«ãƒ«LLMï¼ˆQwen3ï¼‰è¦ç´„æ©Ÿèƒ½ã‚’ä½¿ç”¨")
        else:
            self.news_summarizer = NewsSummarizer(config_path)
            print("â˜ï¸  ã‚¯ãƒ©ã‚¦ãƒ‰APIè¦ç´„æ©Ÿèƒ½ã‚’ä½¿ç”¨")
    
    def process_sales_data(self, csv_file_path: str = None) -> Dict[str, Any]:
        """
        ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ï¼ˆPlacement: å†…å®šæ•°ã€Online Platform: å£²ä¸Šï¼‰
        """
        # Online Platformï¼ˆã‚µãƒ¼ãƒ“ã‚¹Bï¼‰ã®å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹
        online_platform_csv = "/Users/01062544/Downloads/Revenue_non-RAG_jp_weekly_WoW&YoY.csv"
        
        # Placementï¼ˆã‚µãƒ¼ãƒ“ã‚¹Aï¼‰ã®å†…å®šæ•°ãƒ‡ãƒ¼ã‚¿ - å®Ÿãƒ‡ãƒ¼ã‚¿ã«æ›´æ–°
        placement_current = 2739    # ä»Šé€±ã®å†…å®šæ•°
        placement_previous_week = 2550    # å…ˆé€±ã®å†…å®šæ•°
        placement_previous_year = 2916    # æ˜¨å¹´åŒæœŸã®å†…å®šæ•°
        
        # å‰å¹´åŒæœŸæ¯”ã¨å‰é€±æ¯”ã‚’è¨ˆç®—
        placement_yoy_change = ((placement_current - placement_previous_year) / placement_previous_year) * 100
        placement_weekly_change = ((placement_current - placement_previous_week) / placement_previous_week) * 100
        
        placement_data = {
            "name": "Placement",
            "metric_type": "å†…å®šæ•°",
            "current_value": placement_current,
            "previous_year_value": placement_previous_year,
            "previous_week_value": placement_previous_week,
            "yoy_change": round(placement_yoy_change, 1),  # å‰å¹´åŒæœŸæ¯”
            "weekly_change": round(placement_weekly_change, 1)  # å‰é€±æ¯”
        }
        
        # Online Platformï¼ˆã‚µãƒ¼ãƒ“ã‚¹Bï¼‰ã®å£²ä¸Šå®Ÿãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        online_platform_data = self._load_online_platform_data(online_platform_csv)
        
        # ã‚µãƒ¼ãƒ“ã‚¹åˆ¥ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ
        services = [
            placement_data,
            {
                "name": "Online Platform",
                "metric_type": "å£²ä¸Š",
                "current_value": online_platform_data["current_sales"],
                "previous_week_value": online_platform_data.get("previous_week_sales"),
                "previous_year_value": online_platform_data["previous_year_sales"],
                "yoy_change": online_platform_data["yoy_change"],
                "weekly_change": online_platform_data["weekly_change"]
            }
        ]
        
        return {
            "service_count": len(services),
            "services": services
        }
    
    def _load_online_platform_data(self, csv_path: str) -> Dict[str, Any]:
        """
        Online Platformï¼ˆã‚µãƒ¼ãƒ“ã‚¹Bï¼‰ã®å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        """
        try:
            if not os.path.exists(csv_path):
                print(f"âš ï¸  Online Platformãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
                return self._get_dummy_online_platform_data()
            
            df = pd.read_csv(csv_path)
            
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹é€ : this_week_revenue_jpy,last_week_revenue_jpy,last_year_same_week_revenue_jpy,wow_pct,yoy_pct
            row = df.iloc[0]  # æœ€åˆã®è¡Œã‚’å–å¾—
            
            current_sales = int(row['this_week_revenue_jpy'])
            previous_week_sales = int(row['last_week_revenue_jpy'])
            previous_year_sales = int(row['last_year_same_week_revenue_jpy'])
            wow_pct = float(row['wow_pct'])
            yoy_pct = float(row['yoy_pct'])
            
            return {
                "name": "Online Platform",
                "current_sales": current_sales,
                "previous_week_sales": previous_week_sales,
                "previous_year_sales": previous_year_sales,
                "yoy_change": yoy_pct,
                "weekly_change": wow_pct
            }
            
        except Exception as e:
            print(f"âŒ Online Platformãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return self._get_dummy_online_platform_data()
    
    def _get_dummy_online_platform_data(self) -> Dict[str, Any]:
        """
        Online Platformã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
        """
        return {
            "name": "Online Platform",
            "current_sales": 8765432,
            "previous_week_sales": 8987654,
            "previous_year_sales": 9876543,
            "yoy_change": -11.2,
            "weekly_change": -2.5
        }
    
    def fetch_stock_data(self, tickers: List[str]) -> Dict[str, Any]:
        """
        æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ãƒ»å‡¦ç†ï¼ˆæ—¥çµŒå¹³å‡ã¯Yahoo Financeã€ãã®ä»–ã¯Alpha Vantageï¼‰
        """
        stock_data = {}
        
        for ticker in tickers:
            if ticker == "N225":
                # æ—¥çµŒå¹³å‡ã¯Yahoo Finance APIã‚’ä½¿ç”¨
                stock_data[ticker] = self._fetch_nikkei_from_yahoo()
            else:
                # ãã®ä»–ã¯Alpha Vantage APIã‚’ä½¿ç”¨
                stock_data[ticker] = self._fetch_stock_from_alpha_vantage(ticker)
        
        return stock_data
    
    def _fetch_nikkei_from_yahoo(self) -> Dict[str, Any]:
        """
        Yahoo Finance APIã‹ã‚‰æ—¥çµŒå¹³å‡æ ªä¾¡ã‚’å–å¾—
        """
        try:
            import time
            import json
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’é¿ã‘ã‚‹ãŸã‚å°‘ã—å¾…æ©Ÿ
            time.sleep(2)
            
            # è¤‡æ•°ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’è©¦è¡Œ
            urls = [
                "https://query1.finance.yahoo.com/v8/finance/chart/%5EN225",
                "https://query2.finance.yahoo.com/v8/finance/chart/%5EN225"
            ]
            
            headers = {
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                "Accept": "application/json",
                "Accept-Language": "en-US,en;q=0.9",
                "Accept-Encoding": "gzip, deflate, br",
                "Referer": "https://finance.yahoo.com/"
            }
            
            for url in urls:
                try:
                    params = {
                        "interval": "1d",
                        "range": "5d",  # 5æ—¥åˆ†å–å¾—ã—ã¦ã‚ˆã‚Šå®‰å®šã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                        "includePrePost": "false"
                    }
                    
                    response = requests.get(url, params=params, headers=headers, timeout=15)
                    print(f"Yahoo Finance response status: {response.status_code}")
                    
                    if response.status_code == 200:
                        try:
                            data = response.json()
                        except json.JSONDecodeError:
                            print(f"JSON decode error. Response text: {response.text[:200]}")
                            continue
                        
                        if "chart" in data and data["chart"]["result"] and len(data["chart"]["result"]) > 0:
                            result = data["chart"]["result"][0]
                            
                            if "indicators" in result and "quote" in result["indicators"]:
                                closes = result["indicators"]["quote"][0]["close"]
                                
                                # Noneã‚’é™¤å»ã—ã¦æœ‰åŠ¹ãªä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å–å¾—
                                valid_closes = [price for price in closes if price is not None]
                                
                                if len(valid_closes) >= 2:
                                    current_price = valid_closes[-1]  # æœ€æ–°ä¾¡æ ¼
                                    previous_price = valid_closes[-2]  # å‰å–¶æ¥­æ—¥ä¾¡æ ¼
                                    
                                    change = current_price - previous_price
                                    change_percent = (change / previous_price) * 100
                                    
                                    return {
                                        "current_price": round(current_price, 2),
                                        "change": round(change, 2),
                                        "change_percent": round(change_percent, 2)
                                    }
                        
                        print(f"Unexpected data structure: {list(data.keys()) if 'data' in locals() else 'No data'}")
                    
                except requests.exceptions.RequestException as e:
                    print(f"Request error for {url}: {e}")
                    continue
            
            # å…¨ã¦ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§å¤±æ•—ã—ãŸå ´åˆã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤ã‚’è¿”ã™
            print("âš ï¸  Yahoo Finance APIå–å¾—ã«å¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤ã‚’ä½¿ç”¨")
            return {
                "current_price": 38486.29,  # æ­£ç¢ºãªç¾åœ¨å€¤
                "change": -2.05,
                "change_percent": -0.01,
                "note": "Yahoo Finance API unavailable - using fallback value"
            }
                
        except Exception as e:
            print(f"Error fetching Nikkei 225 from Yahoo Finance: {e}")
            return {
                "current_price": 38486.29,  # æ­£ç¢ºãªç¾åœ¨å€¤
                "change": -2.05,
                "change_percent": -0.01,
                "error": f"Yahoo Finance API error: {str(e)}"
            }
    
    def _fetch_stock_from_alpha_vantage(self, ticker: str) -> Dict[str, Any]:
        """
        Alpha Vantage APIã‹ã‚‰æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        """
        try:
            api_key = self.config["data_sources"]["stock_data"]["api_key"]
            url = f"https://www.alphavantage.co/query"
            params = {
                "function": "TIME_SERIES_DAILY",
                "symbol": ticker,
                "apikey": api_key
            }
            response = requests.get(url, params=params)
            data = response.json()
            
            # æœ€æ–°ã®æ ªä¾¡æƒ…å ±ã‚’æŠ½å‡º
            if "Time Series (Daily)" in data:
                time_series = data["Time Series (Daily)"]
                dates = list(time_series.keys())
                if dates:
                    latest_date = dates[0]
                    latest_data = time_series[latest_date]
                    previous_date = dates[1] if len(dates) > 1 else dates[0]
                    previous_data = time_series[previous_date]
                    
                    current_price = float(latest_data["4. close"])
                    previous_price = float(previous_data["4. close"])
                    change = current_price - previous_price
                    change_percent = (change / previous_price) * 100
                    
                    return {
                        "current_price": current_price,
                        "change": round(change, 2),
                        "change_percent": round(change_percent, 2)
                    }
                else:
                    return {"error": "No data available"}
            else:
                return {"error": f"Unexpected response format: {list(data.keys())}"}
                                     
        except Exception as e:
            print(f"Error processing {ticker}: {e}")
            return {"error": str(e)}
    
    def fetch_news_data(self, keywords: List[str]) -> List[Dict[str, Any]]:
        """
        ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ãƒ»å‡¦ç†ï¼ˆéå»1é€±é–“ä»¥å†…ã€è¤‡æ•°ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ä½¿ç”¨ï¼‰
        """
        all_articles = []
        
        # éå»1é€±é–“ã®æ—¥ä»˜ã‚’è¨ˆç®—ï¼ˆ6/16ä»¥é™ç¢ºå®Ÿã«å–å¾—ï¼‰
        from datetime import datetime, timedelta
        one_week_ago = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
        target_date = max(one_week_ago, '2025-06-16')  # 6/16ä»¥é™ã‚’ç¢ºå®Ÿã«å–å¾—
        
        print(f"ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—é–‹å§‹ - å¯¾è±¡æœŸé–“: {target_date}ä»¥é™")
        
        # NewsAPIï¼ˆãƒ¡ã‚¤ãƒ³ã‚½ãƒ¼ã‚¹ï¼‰
        newsapi_articles = self._fetch_from_newsapi(keywords, target_date)
        all_articles.extend(newsapi_articles)
        
        # GNews APIï¼ˆè¿½åŠ ã‚½ãƒ¼ã‚¹ï¼‰
        gnews_articles = self._fetch_from_gnews(keywords, target_date)
        all_articles.extend(gnews_articles)
        
        # é‡è¤‡è¨˜äº‹ã‚’é™¤å»ï¼ˆURLãƒ™ãƒ¼ã‚¹ï¼‰
        seen_urls = set()
        unique_articles = []
        for article in all_articles:
            if article['url'] not in seen_urls:
                seen_urls.add(article['url'])
                unique_articles.append(article)
        
        # æ—¥ä»˜é †ã§ã‚½ãƒ¼ãƒˆã—ã€ä¸Šä½15ä»¶ã‚’å–å¾—
        unique_articles.sort(key=lambda x: x["published_at"], reverse=True)
        selected_articles = unique_articles[:15]
        
        print(f"âœ… ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—å®Œäº† - åˆè¨ˆ{len(unique_articles)}ä»¶ï¼ˆé‡è¤‡é™¤å»å¾Œï¼‰ã€é¸æŠ{len(selected_articles)}ä»¶")
        
        # æ—¥æœ¬èªè¦ç´„ã‚’è¿½åŠ 
        processed_articles = self.news_summarizer.process_news_articles(selected_articles)
        
        return processed_articles
    
    def _fetch_from_newsapi(self, keywords: List[str], from_date: str) -> List[Dict[str, Any]]:
        """NewsAPIã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—"""
        api_key = self.config["data_sources"]["news_data"]["api_key"]
        articles = []
        
        for keyword in keywords:
            try:
                url = "https://newsapi.org/v2/everything"
                params = {
                    "q": keyword,
                    "apiKey": api_key,
                    "language": "en",
                    "sortBy": "publishedAt",
                    "pageSize": 5,
                    "from": from_date
                }
                response = requests.get(url, params=params)
                data = response.json()
                
                if data.get("articles"):
                    for article in data["articles"]:
                        # ã‚ˆã‚Šå¤šãã®æƒ…å ±ã‚’åé›†ï¼ˆtitle + description + contentï¼‰
                        title = article.get("title", "")
                        description = article.get("description", "") or ""
                        content = article.get("content", "") or ""
                        
                        # contentã‹ã‚‰HTMLã‚¿ã‚°ã‚„ãƒã‚¤ã‚ºã‚’é™¤å»
                        import re
                        if content:
                            # ä¸€èˆ¬çš„ãªãƒã‚¤ã‚ºãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤å»
                            content = re.sub(r'[{}\[\]"\'\\]', '', content)
                            content = re.sub(r'window\.open.*?return false;', '', content)
                            content = re.sub(r'https?://[^\s]+', '', content)  # URLã‚’é™¤å»
                            content = re.sub(r'\s+', ' ', content).strip()  # ç©ºç™½ã‚’æ­£è¦åŒ–
                        
                        articles.append({
                            "title": title,
                            "description": description,
                            "content": content,
                            "url": article["url"],
                            "published_at": article["publishedAt"],
                            "keyword": keyword,
                            "source": "NewsAPI"
                        })
            except Exception as e:
                print(f"Error fetching news from NewsAPI for {keyword}: {e}")
        
        return articles
    
    def _fetch_from_gnews(self, keywords: List[str], from_date: str) -> List[Dict[str, Any]]:
        """GNews APIã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—"""
        articles = []
        
        # GNews APIã‚­ãƒ¼ã‚’è¨­å®šã«è¿½åŠ ï¼ˆãƒ•ãƒªãƒ¼ãƒ—ãƒ©ãƒ³ä½¿ç”¨ï¼‰
        gnews_api_key = "your_gnews_api_key_here"  # å®Ÿéš›ã®ã‚­ãƒ¼ã«ç½®ãæ›ãˆ
        
        for keyword in keywords:
            try:
                url = "https://gnews.io/api/v4/search"
                params = {
                    "q": keyword,
                    "token": gnews_api_key,
                    "lang": "en",
                    "country": "us",
                    "max": 5,
                    "from": from_date + "T00:00:00Z"
                }
                response = requests.get(url, params=params)
                
                if response.status_code == 200:
                    data = response.json()
                    
                    if data.get("articles"):
                        for article in data["articles"]:
                            articles.append({
                                "title": article.get("title", ""),
                                "description": article.get("description", ""),
                                "content": article.get("content", ""),  # GNewsã§ã¯åˆ¶é™ã‚ã‚Š
                                "url": article.get("url", ""),
                                "published_at": article.get("publishedAt", ""),
                                "keyword": keyword,
                                "source": "GNews"
                            })
                else:
                    print(f"GNews API error for {keyword}: {response.status_code}")
                    
            except Exception as e:
                print(f"Error fetching news from GNews for {keyword}: {e}")
        
        return articles
    
    def get_weekly_news_summary(self, articles: List[Dict[str, Any]]) -> str:
        """
        é€±é–“ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ
        
        Args:
            articles (List[Dict]): å‡¦ç†æ¸ˆã¿ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ãƒªã‚¹ãƒˆ
        
        Returns:
            str: é€±é–“ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚µãƒãƒªãƒ¼ï¼ˆ300æ–‡å­—ç¨‹åº¦ï¼‰
        """
        return self.news_summarizer.generate_weekly_news_summary(articles)
    
    def format_schedule_data(self, outlook_events: List[Dict]) -> str:
        """
        Outlookã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ•´å½¢
        """
        if not outlook_events:
            return "ä»Šé€±ã¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
        
        formatted_schedule = []
        for event in outlook_events:
            # TODO: å®Ÿéš›ã®Outlookã‚¤ãƒ™ãƒ³ãƒˆæ§‹é€ ã«å¿œã˜ã¦å®Ÿè£…
            formatted_schedule.append(f"â€¢ {event.get('subject', 'ã‚¿ã‚¤ãƒˆãƒ«æœªè¨­å®š')}")
        
        return "\n".join(formatted_schedule)
    
    def generate_html_tables(self, sales_data: Dict, stock_data: Dict) -> Dict[str, str]:
        """
        HTMLãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç”Ÿæˆ
        """
        # ã‚µãƒ¼ãƒ“ã‚¹åˆ¥ãƒ“ã‚¸ãƒã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«
        if sales_data.get("services"):
            service_rows = []
            for service in sales_data["services"]:
                yoy_color = "green" if service.get('yoy_change', 0) > 0 else "red"
                weekly_color = "green" if service.get('weekly_change', 0) > 0 else "red"
                
                # ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦å€¤ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                if service.get('metric_type') == 'å†…å®šæ•°':
                    current_display = f"{service['current_value']:,}ä»¶"
                else:  # å£²ä¸Š
                    current_display = f"Â¥{service['current_value']:,}"
                
                service_rows.append(f"""
                    <tr>
                        <td>{service['name']}</td>
                        <td>{service.get('metric_type', 'N/A')}</td>
                        <td>{current_display}</td>
                        <td style="color: {yoy_color};">{service['yoy_change']}%</td>
                        <td style="color: {weekly_color};">{service['weekly_change']}%</td>
                    </tr>
                """)
            
            sales_table_html = f"""
            <table border="1" style="border-collapse: collapse; width: 100%; margin-top: 10px;">
                <tr style="background-color: #f2f2f2;"><th>ã‚µãƒ¼ãƒ“ã‚¹å</th><th>æŒ‡æ¨™</th><th>ä»Šé€±å®Ÿç¸¾</th><th>å‰å¹´åŒæœŸæ¯”</th><th>å‰é€±æ¯”</th></tr>
                {''.join(service_rows)}
            </table>
            """
        else:
            sales_table_html = "<p>ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚</p>"
        
        # æ ªä¾¡ãƒ†ãƒ¼ãƒ–ãƒ«
        stock_rows = []
        ticker_names = self.config["data_sources"]["stock_data"]["ticker_names"]
        
        for ticker, data in stock_data.items():
            if "error" not in data:
                name = ticker_names.get(ticker, ticker)
                change_color = "green" if data.get('change_percent', 0) > 0 else "red"
                stock_rows.append(f"""
                    <tr>
                        <td>{name} ({ticker})</td>
                        <td>{data.get('current_price', 'N/A')}</td>
                        <td style="color: {change_color};">{data.get('change', 'N/A')}</td>
                        <td style="color: {change_color};">{data.get('change_percent', 'N/A')}%</td>
                    </tr>
                """)
        
        stock_html = f"""
        <table border="1" style="border-collapse: collapse; width: 100%;">
            <tr style="background-color: #f2f2f2;"><th>éŠ˜æŸ„</th><th>ç¾åœ¨ä¾¡æ ¼</th><th>å‰æ—¥å·®</th><th>å‰æ—¥æ¯”</th></tr>
            {''.join(stock_rows)}
        </table>
        """
        
        return {
            "sales_table": sales_table_html,
            "stock_table": stock_html
        }

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œç”¨
    processor = WeeklyReportProcessor()
    
    # ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆï¼ˆäº‹æ¥­åˆ¥ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼‰
    print("=== ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆ ===")
    print("ğŸ“Š Placementï¼ˆå†…å®šæ•°ï¼‰+ Online Platformï¼ˆå£²ä¸Šï¼‰ã®äº‹æ¥­åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ")
    sales_data = processor.process_sales_data()
    print(json.dumps(sales_data, indent=2, ensure_ascii=False))
    
    # ã‚µãƒ³ãƒ—ãƒ«æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆï¼ˆå®Ÿéš›ã®APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆï¼‰
    print("\n=== HTMLãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆãƒ†ã‚¹ãƒˆ ===")
    sample_stock_data = {
        "AAPL": {"current_price": 195.64, "change": 2.34, "change_percent": 1.21},
        "GOOGL": {"current_price": 2750.80, "change": -15.20, "change_percent": -0.55},
        "MSFT": {"current_price": 378.91, "change": 5.67, "change_percent": 1.52}
    }
    
    tables = processor.generate_html_tables(sales_data, sample_stock_data)
    print("å£²ä¸Šãƒ†ãƒ¼ãƒ–ãƒ«:")
    print(tables["sales_table"])
    print("\næ ªä¾¡ãƒ†ãƒ¼ãƒ–ãƒ«:")
    print(tables["stock_table"])
    
    # ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆï¼ˆAPIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ï¼‰
    if processor.config["data_sources"]["news_data"]["api_key"] != "API_KEY_TO_BE_PROVIDED":
        print("\n=== ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆ ===")
        sample_keywords = ["OpenAI", "Anthropic"]
        news_data = processor.fetch_news_data(sample_keywords)
        print(f"å–å¾—è¨˜äº‹æ•°: {len(news_data)}")
    else:
        print("\n=== ãƒ‹ãƒ¥ãƒ¼ã‚¹APIã‚­ãƒ¼ãŒæœªè¨­å®šã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ— ===")
    
    if processor.config["data_sources"]["stock_data"]["api_key"] != "API_KEY_TO_BE_PROVIDED":
        print("\n=== æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆ ===")
        tickers = processor.config["data_sources"]["stock_data"]["tickers"]
        stock_data = processor.fetch_stock_data(tickers)
        print(json.dumps(stock_data, indent=2))
    else:
        print("\n=== æ ªä¾¡APIã‚­ãƒ¼ãŒæœªè¨­å®šã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ— ===") 