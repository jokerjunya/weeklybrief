#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MDãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¦JSONåŒ–ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯:
1. reports/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®æœ€æ–°ã®MDãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
2. ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºãƒ»ãƒ‘ãƒ¼ã‚¹
3. web/news-data.jsonãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦å‡ºåŠ›
4. Webãƒšãƒ¼ã‚¸ã‹ã‚‰èª­ã¿è¾¼ã¿å¯èƒ½ãªJSONå½¢å¼ã§ä¿å­˜

ä½¿ç”¨æ–¹æ³•:
    python scripts/generate-news-json.py
"""

import os
import re
import json
import glob
from datetime import datetime
from typing import Dict, List, Any


def find_latest_report() -> str:
    """æœ€æ–°ã®ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
    reports_dir = "reports"
    pattern = os.path.join(reports_dir, "é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ_ãƒ†ã‚¹ãƒˆ_*.md")
    files = glob.glob(pattern)
    
    if not files:
        raise FileNotFoundError("ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åã®æ—¥æ™‚éƒ¨åˆ†ã§ã‚½ãƒ¼ãƒˆ
    files.sort(reverse=True)
    return files[0]


def parse_news_section(content: str) -> Dict[str, Any]:
    """MDãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡ºãƒ»ãƒ‘ãƒ¼ã‚¹"""
    
    # ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚µãƒãƒªãƒ¼ã‚’æŠ½å‡º
    summary_match = re.search(r'### ğŸ“‹ ä»Šé€±ã®ã‚µãƒãƒªãƒ¼\n\n(.+?)\n\n---', content, re.DOTALL)
    summary = summary_match.group(1).strip() if summary_match else ""
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æŠ½å‡º
    categories = {
        'openai': 'OpenAI',
        'gemini': 'Gemini', 
        'lovable': 'Lovable',
        'perplexity': 'Perplexity',
        'grok': 'Grok',
        'anthropic': 'Anthropic',
        'other': 'ãã®ä»–'
    }
    
    news_data = []
    
    for category_key, category_name in categories.items():
        # ã‚«ãƒ†ã‚´ãƒªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¤œç´¢
        pattern = rf'### ğŸ” {re.escape(category_name)} é–¢é€£\n\n(.*?)(?=### ğŸ”|\n---|\Z)'
        category_match = re.search(pattern, content, re.DOTALL)
        
        if category_match:
            category_content = category_match.group(1)
            
            # è¨˜äº‹ã‚’æŠ½å‡º
            article_pattern = r'\d+\.\s*\*\*\[(.+?)\]\((.+?)\)\*\*\n\s*ğŸ‡¯ğŸ‡µ\s*\*\*è¦ç´„\*\*:\s*(.+?)\n\s*\*(.+?)\*'
            articles = re.findall(article_pattern, category_content, re.DOTALL)
            
            for title, url, summary, time in articles:
                # ã‚«ãƒ†ã‚´ãƒªã‚’æ­£è¦åŒ–
                if category_key in ['lovable', 'perplexity', 'grok', 'anthropic', 'other']:
                    display_category = 'other'
                else:
                    display_category = category_key
                
                news_data.append({
                    'category': display_category,
                    'title': title.strip(),
                    'summary': summary.strip(),
                    'url': url.strip(),
                    'time': time.strip(),
                    'source': category_name
                })
    
    return {
        'summary': summary,
        'articles': news_data,
        'total_articles': len(news_data),
        'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }


def save_news_json(news_data: Dict[str, Any], output_path: str = "web/news-data.json"):
    """ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜"""
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(news_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ãƒ‹ãƒ¥ãƒ¼ã‚¹JSONãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†: {output_path}")
    print(f"ğŸ“Š è¨˜äº‹æ•°: {news_data['total_articles']}ä»¶")
    print(f"ğŸ“… ç”Ÿæˆæ—¥æ™‚: {news_data['generated_at']}")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    try:
        print("ğŸ” æœ€æ–°ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ä¸­...")
        latest_report = find_latest_report()
        print(f"ğŸ“„ å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {latest_report}")
        
        print("ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºä¸­...")
        with open(latest_report, 'r', encoding='utf-8') as f:
            content = f.read()
        
        news_data = parse_news_section(content)
        
        print("ğŸ’¾ JSONãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆä¸­...")
        save_news_json(news_data)
        
        print("\nğŸ‰ å‡¦ç†å®Œäº†ï¼")
        print("ğŸ“ ä½¿ç”¨æ–¹æ³•:")
        print("   1. Webãƒšãƒ¼ã‚¸ã‹ã‚‰ news-data.json ã‚’èª­ã¿è¾¼ã¿")
        print("   2. fetch('news-data.json').then(r => r.json())")
        print("   3. ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãªãƒ‹ãƒ¥ãƒ¼ã‚¹è¡¨ç¤ºã«æ´»ç”¨")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main()) 