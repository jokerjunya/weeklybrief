#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒ­ãƒ¼ã‚«ãƒ«LLMï¼ˆQwen3ï¼‰ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦ç´„æ©Ÿèƒ½

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯Ollamaã‚’ä½¿ç”¨ã—ã¦Qwen3ãƒ¢ãƒ‡ãƒ«ã§
è‹±èªã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’æ—¥æœ¬èªã«è¦ç´„ã—ã¾ã™ã€‚
"""

import json
import requests
import time
from typing import Dict, List, Optional, Any
from datetime import datetime


class LocalLLMSummarizer:
    """
    ãƒ­ãƒ¼ã‚«ãƒ«LLMï¼ˆQwen3ï¼‰ã‚’ä½¿ç”¨ã—ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹è¦ç´„æ©Ÿèƒ½
    """
    
    def __init__(self, config_path: str = "config/settings.json"):
        """
        åˆæœŸåŒ–
        
        Args:
            config_path (str): è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
        
        self.llm_config = self.config["data_sources"].get("local_llm", {})
        self.enabled = self.llm_config.get("enabled", False)
        self.ollama_url = self.llm_config.get("ollama_url", "http://localhost:11434")
        self.model_name = self.llm_config.get("model_name", "qwen3:8b")
        self.thinking_mode = self.llm_config.get("thinking_mode", False)
        
        # æ¥ç¶šãƒ†ã‚¹ãƒˆ
        self.available = self._test_ollama_connection()
    
    def _test_ollama_connection(self) -> bool:
        """
        Ollamaã‚µãƒ¼ãƒãƒ¼ã¨ã®æ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆ
        
        Returns:
            bool: æ¥ç¶šæˆåŠŸã®å ´åˆTrue
        """
        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json().get('models', [])
                # æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
                model_names = [model['name'] for model in models]
                return any(self.model_name in name for name in model_names)
            return False
        except Exception as e:
            print(f"Ollamaæ¥ç¶šãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def generate_summary_japanese(self, title: str, description: str, url: str = "") -> Optional[str]:
        """
        è‹±èªã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‹ã‚‰æ—¥æœ¬èªè¦ç´„ã‚’ç”Ÿæˆ
        
        Args:
            title (str): è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆè‹±èªï¼‰
            description (str): è¨˜äº‹èª¬æ˜ï¼ˆè‹±èªï¼‰
            url (str): è¨˜äº‹URLï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        
        Returns:
            Optional[str]: æ—¥æœ¬èªè¦ç´„ï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
        """
        if not self.enabled or not self.available:
            return self._fallback_summary(title, description)
        
        try:
            return self._summarize_with_qwen3(title, description)
        except Exception as e:
            print(f"Qwen3è¦ç´„ã‚¨ãƒ©ãƒ¼: {e}")
            return self._fallback_summary(title, description)
    
    def _summarize_with_qwen3(self, title: str, description: str) -> Optional[str]:
        """
        Qwen3ã‚’ä½¿ç”¨ã—ã¦æ—¥æœ¬èªè¦ç´„ã‚’ç”Ÿæˆ
        
        Args:
            title (str): è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«
            description (str): è¨˜äº‹èª¬æ˜
        
        Returns:
            Optional[str]: æ—¥æœ¬èªè¦ç´„
        """
        # éthinking modeã‚’å¼·åˆ¶ã—ã€ç›´æ¥çš„ãªæ—¥æœ¬èªè¦ç´„ã‚’ç”Ÿæˆ
        # Qwen3ã®chat templateã‚’ä½¿ç”¨ã—ã¦thinking modeã‚’å›é¿
        prompt = f"""<|user|>
ä»¥ä¸‹ã®è‹±èªã®AIæ¥­ç•Œãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’èª­ã‚“ã§ã€é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’æ—¥æœ¬èªã§50æ–‡å­—ä»¥å†…ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚

ã‚¿ã‚¤ãƒˆãƒ«: {title}
å†…å®¹: {description}

æ—¥æœ¬èªè¦ç´„ã‚’ç°¡æ½”ã«ä½œæˆã—ã¦ãã ã•ã„ã€‚
<|assistant|>
"""
        
        payload = {
            "model": self.model_name,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.3,
                "top_p": 0.8,
                "top_k": 30,
                "num_predict": 100,
                "stop": ["<|user|>", "<|assistant|>", "\n\n"],
                "repeat_penalty": 1.1,
                "seed": 42  # ä¸€è²«æ€§ã®ãŸã‚å›ºå®šã‚·ãƒ¼ãƒ‰
            }
        }
        
        try:
            print(f"ğŸ¤– Qwen3ã§è¦ç´„ç”Ÿæˆä¸­: {title[:30]}...")
            
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json=payload,
                timeout=40
            )
            
            if response.status_code == 200:
                result = response.json()
                raw_summary = result.get('response', '').strip()
                
                print(f"ğŸ“ ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ï¼ˆç”Ÿï¼‰: {raw_summary}")
                
                # thinkingã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å®Œå…¨é™¤å»
                if '<think>' in raw_summary:
                    if '</think>' in raw_summary:
                        # thinkingéƒ¨åˆ†å¾Œã®å†…å®¹ã‚’å–å¾—
                        parts = raw_summary.split('</think>')
                        raw_summary = parts[-1].strip()
                    else:
                        # thinkingé€”ä¸­ã®å ´åˆã¯ã‚ˆã‚Šå¼·åˆ¶çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
                        print("âš ï¸ Thinking mode detected, trying direct approach...")
                        return self._direct_translation_approach(title, description)
                
                # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                summary = self._clean_summary(raw_summary)
                
                # å“è³ªãƒã‚§ãƒƒã‚¯
                if self._is_valid_summary(summary, title, description):
                    print(f"âœ… æœ€çµ‚è¦ç´„: {summary}")
                    return summary
                else:
                    print("âš ï¸ Summary quality check failed, trying direct approach...")
                    return self._direct_translation_approach(title, description)
                    
            else:
                print(f"âŒ Ollama APIã‚¨ãƒ©ãƒ¼: {response.status_code}")
                return self._direct_translation_approach(title, description)
                
        except Exception as e:
            print(f"âŒ Qwen3 APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
            return self._direct_translation_approach(title, description)
    
    def _direct_translation_approach(self, title: str, description: str) -> Optional[str]:
        """
        ã‚ˆã‚Šç›´æ¥çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ç¿»è¨³ãƒ»è¦ç´„
        
        Args:
            title (str): è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«
            description (str): è¨˜äº‹èª¬æ˜
        
        Returns:
            Optional[str]: æ—¥æœ¬èªè¦ç´„
        """
        # æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ç›´æ¥çš„ã«è¦æ±‚
        text_to_summarize = f"{title}. {description}"
        
        prompt = f"""Translate to Japanese and summarize in 50 characters:

{text_to_summarize}

Japanese:"""
        
        payload = {
            "model": self.model_name,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.1,
                "num_predict": 80,
                "stop": ["\n", "English:", "Translate:"],
                "repeat_penalty": 1.2
            }
        }
        
        try:
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json=payload,
                timeout=25
            )
            
            if response.status_code == 200:
                result = response.json()
                summary = result.get('response', '').strip()
                
                # thinking contentãŒã‚ã‚‹å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                if '<think>' in summary:
                    print("âš ï¸ Still in thinking mode, using improved fallback...")
                    return self._improved_fallback_summary(title, description)
                
                summary = self._clean_summary(summary)
                
                if self._is_valid_summary(summary, title, description):
                    return summary
                else:
                    return self._improved_fallback_summary(title, description)
            else:
                return self._improved_fallback_summary(title, description)
                
        except Exception:
            return self._improved_fallback_summary(title, description)
    
    def _is_valid_summary(self, summary: str, title: str, description: str) -> bool:
        """
        è¦ç´„ã®å“è³ªã‚’ãƒã‚§ãƒƒã‚¯
        
        Args:
            summary (str): ç”Ÿæˆã•ã‚ŒãŸè¦ç´„
            title (str): å…ƒã®ã‚¿ã‚¤ãƒˆãƒ«
            description (str): å…ƒã®èª¬æ˜
        
        Returns:
            bool: æœ‰åŠ¹ãªè¦ç´„ã‹ã©ã†ã‹
        """
        if not summary or len(summary) < 10:
            return False
        
        # æ—¥æœ¬èªãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        import re
        has_japanese = bool(re.search(r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF]', summary))
        
        # å…ƒã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ãã®ã¾ã¾ä½¿ã£ã¦ã„ãªã„ã‹ãƒã‚§ãƒƒã‚¯
        title_words = title.lower().split()[:3]  # æœ€åˆã®3å˜èª
        summary_lower = summary.lower()
        
        similarity_count = sum(1 for word in title_words if word in summary_lower)
        too_similar = len(title_words) > 0 and similarity_count >= len(title_words)
        
        return has_japanese and not too_similar
    
    def _improved_fallback_summary(self, title: str, description: str) -> str:
        """
        æ”¹å–„ã•ã‚ŒãŸãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¦ç´„
        descriptionã®å†…å®¹ã‚’åˆ†æã—ã¦ã‚ˆã‚Šæ„å‘³ã®ã‚ã‚‹è¦ç´„ã‚’ä½œæˆ
        
        Args:
            title (str): è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«
            description (str): è¨˜äº‹èª¬æ˜
        
        Returns:
            str: æ—¥æœ¬èªè¦ç´„
        """
        # é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆè‹±èªâ†’æ—¥æœ¬èªï¼‰
        keyword_mapping = {
            "announced": "ç™ºè¡¨",
            "announces": "ç™ºè¡¨",
            "launched": "ãƒªãƒªãƒ¼ã‚¹",
            "launches": "ãƒªãƒªãƒ¼ã‚¹",
            "released": "ãƒªãƒªãƒ¼ã‚¹",
            "releases": "ãƒªãƒªãƒ¼ã‚¹",
            "updated": "æ›´æ–°",
            "updates": "æ›´æ–°",
            "enhanced": "å¼·åŒ–",
            "improved": "æ”¹å–„",
            "new": "æ–°",
            "AI": "AI",
            "artificial intelligence": "AI",
            "model": "ãƒ¢ãƒ‡ãƒ«",
            "technology": "æŠ€è¡“",
            "OpenAI": "OpenAI",
            "Google": "Google",
            "Meta": "Meta",
            "funding": "è³‡é‡‘èª¿é”",
            "investment": "æŠ•è³‡",
            "partnership": "ææº",
            "acquisition": "è²·å",
            "video": "å‹•ç”»",
            "analysis": "åˆ†æ",
            "capabilities": "æ©Ÿèƒ½",
            "performance": "æ€§èƒ½",
            "breakthrough": "ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¹ãƒ«ãƒ¼"
        }
        
        # descriptionã¾ãŸã¯titleã‹ã‚‰é‡è¦ãªæƒ…å ±ã‚’æŠ½å‡º
        content = description if description and len(description) > 20 else title
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ç¿»è¨³ãƒ»è¦ç´„
        summary_parts = []
        
        # ä¼šç¤¾åã‚’ç‰¹å®š
        companies = ["OpenAI", "Google", "Meta", "Microsoft", "Amazon", "Apple", "Anthropic", "Gemini"]
        for company in companies:
            if company.lower() in content.lower():
                summary_parts.append(company)
                break
        
        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç‰¹å®š
        for eng_word, jp_word in keyword_mapping.items():
            if eng_word.lower() in content.lower():
                summary_parts.append(jp_word)
                break
        
        # æŠ€è¡“ãƒ»è£½å“ã‚’ç‰¹å®š
        tech_terms = ["GPT", "model", "AI", "video", "analysis", "tool", "platform", "API"]
        for term in tech_terms:
            if term.lower() in content.lower():
                if term == "model":
                    summary_parts.append("AIãƒ¢ãƒ‡ãƒ«")
                elif term == "video":
                    summary_parts.append("å‹•ç”»")
                elif term == "analysis":
                    summary_parts.append("åˆ†æ")
                else:
                    summary_parts.append(term)
                break
        
        # è¦ç´„ã‚’æ§‹ç¯‰
        if summary_parts:
            summary = "".join(summary_parts[:3]) + "é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹"
        else:
            # æœ€ä½é™ã®æƒ…å ±
            first_sentence = content.split('.')[0] if '.' in content else content
            summary = f"AIæ¥­ç•Œ: {first_sentence[:20]}..."
        
        # 50æ–‡å­—åˆ¶é™
        if len(summary) > 50:
            summary = summary[:47] + "..."
        
        return summary
    
    def _clean_summary(self, summary: str) -> str:
        """
        è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        
        Args:
            summary (str): ç”Ÿã®è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆ
        
        Returns:
            str: ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã•ã‚ŒãŸè¦ç´„
        """
        # ä¸è¦ãªå‰ç½®ãã‚„è¨˜å·ã‚’é™¤å»
        prefixes_to_remove = [
            "æ—¥æœ¬èªè¦ç´„:",
            "è¦ç´„:",
            "ã¾ã¨ã‚:",
            "æ¦‚è¦:",
            "Japanese Summary:",
            "Japanese:",
            "Summary:",
            "ã“ã®è¨˜äº‹ã¯",
            "ã“ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯",
            "**",
            "##",
            "- "
        ]
        
        for prefix in prefixes_to_remove:
            if summary.startswith(prefix):
                summary = summary[len(prefix):].strip()
        
        # æ”¹è¡Œã‚’é™¤å»
        summary = summary.replace('\n', ' ').replace('\r', ' ')
        
        # è¤‡æ•°ã‚¹ãƒšãƒ¼ã‚¹ã‚’å˜ä¸€ã‚¹ãƒšãƒ¼ã‚¹ã«
        import re
        summary = re.sub(r'\s+', ' ', summary)
        
        # 50æ–‡å­—åˆ¶é™
        if len(summary) > 50:
            summary = summary[:47] + "..."
        
        return summary.strip()
    
    def _fallback_summary(self, title: str, description: str) -> str:
        """
        ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¦ç´„ï¼ˆLLMãŒåˆ©ç”¨ã§ããªã„å ´åˆï¼‰
        æ”¹å–„ç‰ˆï¼šdescriptionã®å†…å®¹ã‚‚è€ƒæ…®
        
        Args:
            title (str): è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«
            description (str): è¨˜äº‹èª¬æ˜
        
        Returns:
            str: ç°¡æ˜“è¦ç´„
        """
        # descriptionã‹ã‚‰é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        important_keywords = [
            "AI", "artificial intelligence", "machine learning", "ChatGPT", "GPT",
            "model", "technology", "startup", "funding", "release", "launch",
            "announce", "update", "improve", "enhance", "breakthrough"
        ]
        
        content = description if description else title
        
        # é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€æ–‡ã‚’å„ªå…ˆ
        sentences = content.split('.')
        best_sentence = ""
        
        for sentence in sentences:
            if any(keyword.lower() in sentence.lower() for keyword in important_keywords):
                best_sentence = sentence.strip()
                break
        
        if not best_sentence:
            best_sentence = sentences[0] if sentences else title
        
        # æ—¥æœ¬èªãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’è¿½åŠ 
        summary = f"AIæ¥­ç•Œ: {best_sentence}"
        
        if len(summary) > 47:
            summary = summary[:47] + "..."
        
        return summary
    
    def process_news_articles(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ãƒªã‚¹ãƒˆã‚’å‡¦ç†ã—ã¦æ—¥æœ¬èªè¦ç´„ã‚’è¿½åŠ 
        
        Args:
            articles (List[Dict]): ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ãƒªã‚¹ãƒˆ
        
        Returns:
            List[Dict]: æ—¥æœ¬èªè¦ç´„ä»˜ããƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ãƒªã‚¹ãƒˆ
        """
        processed_articles = []
        
        for i, article in enumerate(articles):
            processed_article = article.copy()
            
            print(f"ğŸ“ è¨˜äº‹ {i+1}/{len(articles)} ã‚’è¦ç´„ä¸­...")
            
            # æ—¥æœ¬èªè¦ç´„ã‚’ç”Ÿæˆ
            summary_jp = self.generate_summary_japanese(
                title=article.get("title", ""),
                description=article.get("description", ""),
                url=article.get("url", "")
            )
            
            processed_article["summary_jp"] = summary_jp
            processed_articles.append(processed_article)
            
            # APIå‘¼ã³å‡ºã—é–“éš”ã‚’èª¿æ•´ï¼ˆOllamaã‚µãƒ¼ãƒãƒ¼ã®è² è·è»½æ¸›ï¼‰
            if i < len(articles) - 1:
                time.sleep(1)
        
        return processed_articles
    
    def get_status(self) -> Dict[str, Any]:
        """
        ãƒ­ãƒ¼ã‚«ãƒ«LLMæ©Ÿèƒ½ã®çŠ¶æ…‹ã‚’å–å¾—
        
        Returns:
            Dict: çŠ¶æ…‹æƒ…å ±
        """
        return {
            "enabled": self.enabled,
            "model_name": self.model_name,
            "ollama_available": self.available,
            "ollama_url": self.ollama_url,
            "thinking_mode": self.thinking_mode,
            "fallback_enabled": True
        }


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    summarizer = LocalLLMSummarizer()
    
    print("=== ãƒ­ãƒ¼ã‚«ãƒ«LLMï¼ˆQwen3ï¼‰è¦ç´„æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ ===")
    status = summarizer.get_status()
    print(f"çŠ¶æ…‹: {status}")
    
    # ã‚µãƒ³ãƒ—ãƒ«è¨˜äº‹ã§ãƒ†ã‚¹ãƒˆ
    sample_articles = [
        {
            "title": "OpenAI announces new GPT-5 model with enhanced reasoning capabilities",
            "description": "The latest AI model from OpenAI shows significant improvements in logical reasoning, mathematics, and code generation, outperforming previous versions in benchmark tests.",
            "url": "https://example.com/openai-gpt5",
            "keyword": "OpenAI"
        },
        {
            "title": "Google's Gemini AI now supports video analysis and understanding",
            "description": "Google has updated its Gemini AI model to include advanced video processing capabilities, allowing users to analyze and interact with video content in natural language.",
            "url": "https://example.com/gemini-video",
            "keyword": "Gemini"
        }
    ]
    
    if summarizer.enabled:
        print("\n=== è¦ç´„ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
        processed = summarizer.process_news_articles(sample_articles)
        
        print("\n=== å‡¦ç†çµæœ ===")
        for article in processed:
            print(f"ğŸ“° ã‚¿ã‚¤ãƒˆãƒ«: {article['title'][:50]}...")
            print(f"ğŸ‡¯ğŸ‡µ æ—¥æœ¬èªè¦ç´„: {article.get('summary_jp', 'æœªç”Ÿæˆ')}")
            print("---")
    else:
        print("âš ï¸  ãƒ­ãƒ¼ã‚«ãƒ«LLMæ©Ÿèƒ½ãŒç„¡åŠ¹ã¾ãŸã¯OllamaãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        print("Ollamaã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:")
        print("  ollama pull qwen3:8b")
        print("  ollama serve") 