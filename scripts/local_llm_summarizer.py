#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒ­ãƒ¼ã‚«ãƒ«LLMï¼ˆQwen3ï¼‰ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦ç´„æ©Ÿèƒ½

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯Ollamaã‚’ä½¿ç”¨ã—ã¦Qwen3ãƒ¢ãƒ‡ãƒ«ã§
è‹±èªã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’æ—¥æœ¬èªã«è¦ç´„ã—ã¾ã™ã€‚
"""

import json
import requests
import time
from typing import Dict, List, Optional, Any
from datetime import datetime


class LocalLLMSummarizer:
    """
    ãƒ­ãƒ¼ã‚«ãƒ«LLMï¼ˆQwen3ï¼‰ã‚’ä½¿ç”¨ã—ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹è¦ç´„æ©Ÿèƒ½
    """
    
    def __init__(self, config_path: str = "config/settings.json"):
        """
        åˆæœŸåŒ–
        
        Args:
            config_path (str): è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
        
        self.llm_config = self.config["data_sources"].get("local_llm", {})
        self.enabled = self.llm_config.get("enabled", False)
        self.ollama_url = self.llm_config.get("ollama_url", "http://localhost:11434")
        self.model_name = self.llm_config.get("model_name", "qwen3:8b")
        self.thinking_mode = self.llm_config.get("thinking_mode", False)
        
        # æ¥ç¶šãƒ†ã‚¹ãƒˆ
        self.available = self._test_ollama_connection()
    
    def _test_ollama_connection(self) -> bool:
        """
        Ollamaã‚µãƒ¼ãƒãƒ¼ã¨ã®æ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆ
        
        Returns:
            bool: æ¥ç¶šæˆåŠŸã®å ´åˆTrue
        """
        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json().get('models', [])
                # æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
                model_names = [model['name'] for model in models]
                return any(self.model_name in name for name in model_names)
            return False
        except Exception as e:
            print(f"Ollamaæ¥ç¶šãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def generate_summary_japanese(self, title: str, description: str, url: str = "") -> Optional[str]:
        """
        è‹±èªã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‹ã‚‰æ—¥æœ¬èªè¦ç´„ã‚’ç”Ÿæˆ
        
        Args:
            title (str): è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆè‹±èªï¼‰
            description (str): è¨˜äº‹èª¬æ˜ï¼ˆè‹±èªï¼‰
            url (str): è¨˜äº‹URLï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        
        Returns:
            Optional[str]: æ—¥æœ¬èªè¦ç´„ï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
        """
        if not self.enabled or not self.available:
            return self._fallback_summary(title, description)
        
        try:
            return self._summarize_with_qwen3(title, description)
        except Exception as e:
            print(f"Qwen3è¦ç´„ã‚¨ãƒ©ãƒ¼: {e}")
            return self._fallback_summary(title, description)
    
    def _summarize_with_qwen3(self, title: str, description: str) -> Optional[str]:
        """
        Qwen3ã‚’ä½¿ç”¨ã—ã¦æ—¥æœ¬èªè¦ç´„ã‚’ç”Ÿæˆ
        
        Args:
            title (str): è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«
            description (str): è¨˜äº‹èª¬æ˜
        
        Returns:
            Optional[str]: æ—¥æœ¬èªè¦ç´„
        """
        # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§thinking modeã‚’å›é¿
        prompt = f"""ä»¥ä¸‹ã®è‹±èªãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ—¥æœ¬èªã§50æ–‡å­—ä»¥å†…ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚

Title: {title}
Content: {description}

Japanese Summary:"""
        
        payload = {
            "model": self.model_name,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.1,  # ã‚ˆã‚Šä½ã„æ¸©åº¦ã§ä¸€è²«æ€§å‘ä¸Š
                "top_p": 0.9,
                "top_k": 40,
                "num_predict": 80,  # çŸ­ã„åˆ¶é™ã§è¿…é€Ÿå¿œç­”
                "stop": ["\n", "Summary:", "è¦ç´„:", "Title:", "Content:"]
            }
        }
        
        try:
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json=payload,
                timeout=30  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’çŸ­ãã—ã¦ãƒ†ã‚¹ãƒˆ
            )
            
            if response.status_code == 200:
                result = response.json()
                summary = result.get('response', '').strip()
                
                # Thinking contentã‚’å®Œå…¨ã«é™¤å»
                if '<think>' in summary:
                    if '</think>' in summary:
                        summary = summary.split('</think>')[-1].strip()
                    else:
                        # Thinkingä¸­ã§æ­¢ã¾ã£ãŸå ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                        return self._fallback_summary(title, description)
                
                # ä¸è¦ãªå‰ç½®ãã‚’é™¤å»
                summary = self._clean_summary(summary)
                
                return summary if summary else None
            else:
                print(f"Ollama APIã‚¨ãƒ©ãƒ¼: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"Qwen3 APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _clean_summary(self, summary: str) -> str:
        """
        è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        
        Args:
            summary (str): ç”Ÿã®è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆ
        
        Returns:
            str: ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã•ã‚ŒãŸè¦ç´„
        """
        # ä¸è¦ãªå‰ç½®ãã‚’é™¤å»
        prefixes_to_remove = [
            "æ—¥æœ¬èªè¦ç´„:",
            "è¦ç´„:",
            "ã¾ã¨ã‚:",
            "æ¦‚è¦:",
            "ã“ã®è¨˜äº‹ã¯",
            "ã“ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯"
        ]
        
        for prefix in prefixes_to_remove:
            if summary.startswith(prefix):
                summary = summary[len(prefix):].strip()
        
        # 50æ–‡å­—åˆ¶é™
        if len(summary) > 50:
            summary = summary[:47] + "..."
        
        return summary
    
    def _fallback_summary(self, title: str, description: str) -> str:
        """
        ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¦ç´„ï¼ˆLLMãŒåˆ©ç”¨ã§ããªã„å ´åˆï¼‰
        
        Args:
            title (str): è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«
            description (str): è¨˜äº‹èª¬æ˜
        
        Returns:
            str: ç°¡æ˜“è¦ç´„
        """
        # ç°¡å˜ãªè‹±èªã‚¿ã‚¤ãƒˆãƒ«ã®çœç•¥ç‰ˆã‚’ä½œæˆ
        content = f"{title}"
        if len(content) > 47:
            content = content[:47] + "..."
        return f"AIæ¥­ç•Œ: {content}"
    
    def process_news_articles(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ãƒªã‚¹ãƒˆã‚’å‡¦ç†ã—ã¦æ—¥æœ¬èªè¦ç´„ã‚’è¿½åŠ 
        
        Args:
            articles (List[Dict]): ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ãƒªã‚¹ãƒˆ
        
        Returns:
            List[Dict]: æ—¥æœ¬èªè¦ç´„ä»˜ããƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ãƒªã‚¹ãƒˆ
        """
        processed_articles = []
        
        for i, article in enumerate(articles):
            processed_article = article.copy()
            
            print(f"ğŸ“ è¨˜äº‹ {i+1}/{len(articles)} ã‚’è¦ç´„ä¸­...")
            
            # æ—¥æœ¬èªè¦ç´„ã‚’ç”Ÿæˆ
            summary_jp = self.generate_summary_japanese(
                title=article.get("title", ""),
                description=article.get("description", ""),
                url=article.get("url", "")
            )
            
            processed_article["summary_jp"] = summary_jp
            processed_articles.append(processed_article)
            
            # APIå‘¼ã³å‡ºã—é–“éš”ã‚’èª¿æ•´ï¼ˆOllamaã‚µãƒ¼ãƒãƒ¼ã®è² è·è»½æ¸›ï¼‰
            if i < len(articles) - 1:
                time.sleep(1)
        
        return processed_articles
    
    def get_status(self) -> Dict[str, Any]:
        """
        ãƒ­ãƒ¼ã‚«ãƒ«LLMæ©Ÿèƒ½ã®çŠ¶æ…‹ã‚’å–å¾—
        
        Returns:
            Dict: çŠ¶æ…‹æƒ…å ±
        """
        return {
            "enabled": self.enabled,
            "model_name": self.model_name,
            "ollama_available": self.available,
            "ollama_url": self.ollama_url,
            "thinking_mode": self.thinking_mode,
            "fallback_enabled": True
        }


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    summarizer = LocalLLMSummarizer()
    
    print("=== ãƒ­ãƒ¼ã‚«ãƒ«LLMï¼ˆQwen3ï¼‰è¦ç´„æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ ===")
    status = summarizer.get_status()
    print(f"çŠ¶æ…‹: {status}")
    
    # ã‚µãƒ³ãƒ—ãƒ«è¨˜äº‹ã§ãƒ†ã‚¹ãƒˆ
    sample_articles = [
        {
            "title": "OpenAI announces new GPT-5 model with enhanced reasoning capabilities",
            "description": "The latest AI model from OpenAI shows significant improvements in logical reasoning, mathematics, and code generation, outperforming previous versions in benchmark tests.",
            "url": "https://example.com/openai-gpt5",
            "keyword": "OpenAI"
        },
        {
            "title": "Google's Gemini AI now supports video analysis and understanding",
            "description": "Google has updated its Gemini AI model to include advanced video processing capabilities, allowing users to analyze and interact with video content in natural language.",
            "url": "https://example.com/gemini-video",
            "keyword": "Gemini"
        }
    ]
    
    if summarizer.enabled:
        print("\n=== è¦ç´„ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
        processed = summarizer.process_news_articles(sample_articles)
        
        print("\n=== å‡¦ç†çµæœ ===")
        for article in processed:
            print(f"ğŸ“° ã‚¿ã‚¤ãƒˆãƒ«: {article['title'][:50]}...")
            print(f"ğŸ‡¯ğŸ‡µ æ—¥æœ¬èªè¦ç´„: {article.get('summary_jp', 'æœªç”Ÿæˆ')}")
            print("---")
    else:
        print("âš ï¸  ãƒ­ãƒ¼ã‚«ãƒ«LLMæ©Ÿèƒ½ãŒç„¡åŠ¹ã¾ãŸã¯OllamaãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        print("Ollamaã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:")
        print("  ollama pull qwen3:8b")
        print("  ollama serve") 