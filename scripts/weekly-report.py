#!/usr/bin/env python3
"""
é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆçµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãƒ‡ãƒ¼ã‚¿åé›† â†’ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã®ä¸€é€£ã®æµã‚Œã‚’å®Ÿè¡Œ
"""

import os
import sys
import asyncio
import argparse
from datetime import datetime

# æ—¢å­˜ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# ãƒ‡ãƒ¼ã‚¿åé›†ã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã®ã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
exec(open('scripts/data-collector.py').read())
exec(open('scripts/report-generator.py').read())

class WeeklyReportPipeline:
    def __init__(self, cache_hours=6):
        """
        é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
        
        Args:
            cache_hours (int): ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹æ™‚é–“
        """
        self.collector = DataCollector(cache_hours=cache_hours)
        self.generator = ReportGenerator()
    
    async def run_full_pipeline(self, force_refresh=False, output_prefix="é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ_ãƒ†ã‚¹ãƒˆ"):
        """
        å®Œå…¨ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œ
        
        Args:
            force_refresh (bool): ãƒ‡ãƒ¼ã‚¿å¼·åˆ¶æ›´æ–°ãƒ•ãƒ©ã‚°
            output_prefix (str): ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«åãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹
        
        Returns:
            dict: å®Ÿè¡Œçµæœ
        """
        print("ğŸš€ é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹")
        print("="*60)
        
        start_time = datetime.now()
        
        try:
            # Phase 1: ãƒ‡ãƒ¼ã‚¿åé›†
            print("\nğŸ“Š Phase 1: ãƒ‡ãƒ¼ã‚¿åé›†")
            print("-" * 30)
            
            data = await self.collector.collect_all_data(force_refresh=force_refresh)
            
            # Phase 2: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            print("\nğŸ“„ Phase 2: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")
            print("-" * 30)
            
            generated_files = self.generator.generate_all_reports(output_prefix=output_prefix)
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            # çµæœã‚µãƒãƒªãƒ¼
            print("\n" + "="*60)
            print("âœ… é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†")
            print("="*60)
            print(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {duration:.2f}ç§’")
            print(f"ğŸ“… ãƒ‡ãƒ¼ã‚¿æœŸé–“: {data['metadata']['data_period']}")
            print(f"ğŸ“Š ãƒ“ã‚¸ãƒã‚¹ã‚µãƒ¼ãƒ“ã‚¹: {len(data['business_data']['services'])}ä»¶")
            print(f"ğŸ“ˆ æ ªä¾¡éŠ˜æŸ„: {len(data['stock_data'])}ä»¶")
            print(f"ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹: {len(data['news_data']['articles'])}ä»¶")
            print(f"ğŸ“… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«: {len(data['schedule_data'])}ä»¶")
            print("\nğŸ“„ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«:")
            for format_type, file_path in generated_files.items():
                print(f"   âœ… {format_type}: {file_path}")
            print("="*60)
            
            return {
                "success": True,
                "duration": duration,
                "data_summary": {
                    "period": data['metadata']['data_period'],
                    "business_services": len(data['business_data']['services']),
                    "stock_tickers": len(data['stock_data']),
                    "news_articles": len(data['news_data']['articles']),
                    "schedule_items": len(data['schedule_data'])
                },
                "generated_files": generated_files
            }
            
        except Exception as e:
            print(f"\nâŒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "success": False,
                "error": str(e)
            }

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(description='é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆçµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³')
    parser.add_argument('--force', action='store_true', help='ãƒ‡ãƒ¼ã‚¿ã‚’å¼·åˆ¶æ›´æ–°')
    parser.add_argument('--cache-hours', type=int, default=6, help='ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹æ™‚é–“ï¼ˆæ™‚é–“ï¼‰')
    parser.add_argument('--prefix', default='é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ_ãƒ†ã‚¹ãƒˆ', help='ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«åãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹')
    parser.add_argument('--data-only', action='store_true', help='ãƒ‡ãƒ¼ã‚¿åé›†ã®ã¿å®Ÿè¡Œ')
    parser.add_argument('--report-only', action='store_true', help='ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã®ã¿å®Ÿè¡Œ')
    
    args = parser.parse_args()
    
    if args.data_only and args.report_only:
        print("âŒ --data-only ã¨ --report-only ã¯åŒæ™‚ã«æŒ‡å®šã§ãã¾ã›ã‚“")
        sys.exit(1)
    
    try:
        if args.data_only:
            # ãƒ‡ãƒ¼ã‚¿åé›†ã®ã¿
            print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿åé›†ã®ã¿å®Ÿè¡Œ")
            collector = DataCollector(cache_hours=args.cache_hours)
            data = await collector.collect_all_data(force_refresh=args.force)
            print("âœ… ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†")
            
        elif args.report_only:
            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã®ã¿
            print("ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã®ã¿å®Ÿè¡Œ")
            generator = ReportGenerator()
            generated_files = generator.generate_all_reports(output_prefix=args.prefix)
            print("âœ… ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†")
            
        else:
            # å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
            pipeline = WeeklyReportPipeline(cache_hours=args.cache_hours)
            result = await pipeline.run_full_pipeline(
                force_refresh=args.force,
                output_prefix=args.prefix
            )
            
            if not result["success"]:
                sys.exit(1)
    
    except KeyboardInterrupt:
        print("\nâš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main()) 