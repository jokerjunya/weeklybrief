#!/usr/bin/env python3
"""
Enhanced DeepResearch - å¤šæ®µéšæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³

æ—¢å­˜ã®Qwen3Llmã‚’ç¶™æ‰¿ã—ã€ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’è¿½åŠ ï¼š
- Chain-of-Thoughtæ¨è«–
- å¤šæ®µéšå•é¡Œåˆ†è§£
- åå¾©çš„åˆ†æãƒ»æ”¹å–„
- æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹è¨˜éŒ²
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'scripts'))

from qwen3_llm import Qwen3Llm
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
from datetime import datetime
import json
import asyncio

@dataclass
class ThinkingStep:
    """æ€è€ƒã‚¹ãƒ†ãƒƒãƒ—ã®è¨˜éŒ²"""
    step_id: int
    phase: str  # "decomposition", "reasoning", "verification", "improvement"
    input_data: str
    output_data: str
    confidence: float
    timestamp: datetime = field(default_factory=datetime.now)
    reasoning_chain: List[str] = field(default_factory=list)

@dataclass
class ResearchResult:
    """æ·±å±¤åˆ†æçµæœ"""
    topic: str
    final_answer: str
    confidence_score: float
    thinking_steps: List[ThinkingStep]
    verification_results: Dict[str, Any]
    sources_analyzed: List[str]
    time_taken: float
    quality_metrics: Dict[str, float]

class EnhancedQwen3Llm(Qwen3Llm):
    """
    Qwen3ãƒ™ãƒ¼ã‚¹å¤šæ®µéšæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³
    
    æ—¢å­˜ã®Qwen3Llmã‚¯ãƒ©ã‚¹ã‚’ç¶™æ‰¿ã—ã€ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’è¿½åŠ ï¼š
    - å¤šæ®µéšæ¨è«–æ©Ÿèƒ½
    - æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹å¯è¦–åŒ–
    - å“è³ªæ¤œè¨¼
    - åå¾©æ”¹å–„
    """
    
    def __init__(self, model="ollama/qwen3:30b-a3b", api_url="http://localhost:11434/api/generate"):
        super().__init__(model, api_url)
        self.thinking_mode = True
        self.steps_log: List[ThinkingStep] = []
        self.current_step_id = 0
        
        # æ¨è«–è¨­å®š
        self.reasoning_config = {
            "max_decomposition_depth": 3,
            "min_confidence_threshold": 0.7,
            "max_iterations": 5,
            "verification_required": True
        }
    
    async def deep_research(self, topic: str, context: Dict[str, Any] = None) -> ResearchResult:
        """
        å¤šæ®µéšæ·±å±¤åˆ†æã®ãƒ¡ã‚¤ãƒ³ãƒ¡ã‚½ãƒƒãƒ‰
        
        Args:
            topic: åˆ†æå¯¾è±¡ãƒˆãƒ”ãƒƒã‚¯
            context: è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
        
        Returns:
            ResearchResult: åˆ†æçµæœ
        """
        start_time = datetime.now()
        self.steps_log = []
        self.current_step_id = 0
        
        try:
            print(f"ğŸ” Deep Researché–‹å§‹: {topic}")
            
            # Phase 1: å•é¡Œåˆ†è§£
            decomposition = await self._decompose_problem(topic, context or {})
            
            # Phase 2: åå¾©æ¨è«–
            reasoning_results = await self._iterative_reasoning(decomposition)
            
            # Phase 3: æ¤œè¨¼ãƒ»æ”¹å–„
            verified_result = await self._verify_and_improve(reasoning_results)
            
            # Phase 4: æœ€çµ‚çµ±åˆ
            final_answer = await self._synthesize_final_answer(verified_result)
            
            end_time = datetime.now()
            time_taken = (end_time - start_time).total_seconds()
            
            # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
            quality_metrics = self._calculate_quality_metrics()
            
            result = ResearchResult(
                topic=topic,
                final_answer=final_answer["answer"],
                confidence_score=final_answer["confidence"],
                thinking_steps=self.steps_log,
                verification_results=verified_result["verification_results"],
                sources_analyzed=verified_result["sources"],
                time_taken=time_taken,
                quality_metrics=quality_metrics
            )
            
            print(f"âœ… Deep Researchå®Œäº†: {time_taken:.2f}ç§’")
            return result
            
        except Exception as e:
            print(f"âŒ Deep Research ã‚¨ãƒ©ãƒ¼: {e}")
            # æœ€å°é™ã®çµæœã‚’è¿”ã™
            return ResearchResult(
                topic=topic,
                final_answer=f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
                confidence_score=0.0,
                thinking_steps=self.steps_log,
                verification_results={},
                sources_analyzed=[],
                time_taken=0.0,
                quality_metrics={}
            )
    
    async def _decompose_problem(self, topic: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """å•é¡Œåˆ†è§£ãƒ•ã‚§ãƒ¼ã‚º"""
        self.current_step_id += 1
        
        decomposition_prompt = f"""ã‚ãªãŸã¯é«˜åº¦ãªåˆ†æã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’ä½“ç³»çš„ã«åˆ†è§£ã—ã¦ãã ã•ã„ã€‚

ãƒˆãƒ”ãƒƒã‚¯: {topic}
ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {json.dumps(context, ensure_ascii=False, indent=2)}

ä»¥ä¸‹ã®æ§‹é€ ã§åˆ†è§£ã—ã¦ãã ã•ã„ï¼š
1. ä¸»è¦ãªåˆ†æè»¸ï¼ˆ3-5å€‹ï¼‰
2. å„è»¸ã§ã®å…·ä½“çš„è³ªå•
3. å¿…è¦ãªæƒ…å ±æº
4. åˆ†æã®å„ªå…ˆé †ä½

å›ç­”ã¯ä»¥ä¸‹ã®JSONå½¢å¼ã§ï¼š
{{
    "analysis_axes": [
        {{
            "axis": "æŠ€è¡“çš„å´é¢",
            "questions": ["å…·ä½“çš„ãªæŠ€è¡“ã¯ä½•ã‹ï¼Ÿ", "é©æ–°æ€§ã¯ï¼Ÿ"],
            "priority": 1
        }}
    ],
    "information_sources": ["ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹", "æŠ€è¡“æ–‡æ›¸"],
    "complexity_level": "é«˜",
    "estimated_depth": 3
}}
"""
        
        response = await self.generate_content_async(
            decomposition_prompt, 
            agent_name="å•é¡Œåˆ†è§£ã‚¨ãƒ³ã‚¸ãƒ³"
        )
        
        try:
            decomposition_data = json.loads(response.strip())
        except:
            # JSONãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            decomposition_data = {
                "analysis_axes": [{"axis": "åŸºæœ¬åˆ†æ", "questions": [topic], "priority": 1}],
                "information_sources": ["ä¸€èˆ¬æƒ…å ±"],
                "complexity_level": "ä¸­",
                "estimated_depth": 1
            }
        
        # æ€è€ƒã‚¹ãƒ†ãƒƒãƒ—ã‚’è¨˜éŒ²
        step = ThinkingStep(
            step_id=self.current_step_id,
            phase="decomposition",
            input_data=topic,
            output_data=json.dumps(decomposition_data, ensure_ascii=False),
            confidence=0.8,
            reasoning_chain=[f"ãƒˆãƒ”ãƒƒã‚¯ '{topic}' ã‚’ {len(decomposition_data.get('analysis_axes', []))} ã®åˆ†æè»¸ã«åˆ†è§£"]
        )
        self.steps_log.append(step)
        
        return decomposition_data
    
    async def _iterative_reasoning(self, decomposition: Dict[str, Any]) -> Dict[str, Any]:
        """åå¾©æ¨è«–ãƒ•ã‚§ãƒ¼ã‚º"""
        reasoning_results = {
            "axis_results": [],
            "confidence_scores": [],
            "reasoning_chains": []
        }
        
        analysis_axes = decomposition.get("analysis_axes", [])
        
        for axis_data in analysis_axes:
            self.current_step_id += 1
            axis_name = axis_data.get("axis", "ä¸æ˜ãªè»¸")
            questions = axis_data.get("questions", [])
            
            print(f"ğŸ¤” åˆ†æè»¸: {axis_name}")
            
            # å„è»¸ã§ã®æ¨è«–å®Ÿè¡Œ
            axis_result = await self._reason_on_axis(axis_name, questions)
            reasoning_results["axis_results"].append(axis_result)
            reasoning_results["confidence_scores"].append(axis_result["confidence"])
            reasoning_results["reasoning_chains"].extend(axis_result["reasoning_chain"])
            
            # æ€è€ƒã‚¹ãƒ†ãƒƒãƒ—è¨˜éŒ²
            step = ThinkingStep(
                step_id=self.current_step_id,
                phase="reasoning",
                input_data=f"è»¸: {axis_name}, è³ªå•: {questions}",
                output_data=json.dumps(axis_result, ensure_ascii=False),
                confidence=axis_result["confidence"],
                reasoning_chain=axis_result["reasoning_chain"]
            )
            self.steps_log.append(step)
        
        return reasoning_results
    
    async def _reason_on_axis(self, axis_name: str, questions: List[str]) -> Dict[str, Any]:
        """ç‰¹å®šã®åˆ†æè»¸ã§ã®æ¨è«–"""
        questions_text = "\n".join([f"- {q}" for q in questions])
        
        reasoning_prompt = f"""åˆ†æè»¸: {axis_name}

ä»¥ä¸‹ã®è³ªå•ã«ã¤ã„ã¦æ®µéšçš„ã«æ¨è«–ã—ã¦ãã ã•ã„ï¼š
{questions_text}

æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹:
1. å„è³ªå•ã«å¯¾ã™ã‚‹åˆæœŸå›ç­”
2. å›ç­”é–“ã®é–¢é€£æ€§åˆ†æ
3. çŸ›ç›¾ç‚¹ã®ç‰¹å®šã¨è§£æ±º
4. çµ±åˆã•ã‚ŒãŸçµè«–

å›ç­”ã¯ä»¥ä¸‹ã®JSONå½¢å¼ã§ï¼š
{{
    "axis_name": "{axis_name}",
    "initial_answers": {{"è³ªå•1": "å›ç­”1"}},
    "relationships": ["é–¢é€£æ€§1", "é–¢é€£æ€§2"],
    "contradictions": ["çŸ›ç›¾ç‚¹1"],
    "integrated_conclusion": "çµ±åˆçµè«–",
    "confidence": 0.8,
    "reasoning_chain": ["æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—1", "æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—2"]
}}
"""
        
        response = await self.generate_content_async(
            reasoning_prompt,
            agent_name=f"æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³({axis_name})"
        )
        
        try:
            axis_result = json.loads(response.strip())
            # åŸºæœ¬çš„ãªä¿¡é ¼åº¦ãƒã‚§ãƒƒã‚¯
            confidence = axis_result.get("confidence", 0.5)
            if confidence < self.reasoning_config["min_confidence_threshold"]:
                print(f"âš ï¸ ä½ä¿¡é ¼åº¦æ¤œå‡º ({confidence:.2f}) - å†æ¨è«–ã‚’å®Ÿè¡Œ")
                # å†æ¨è«–ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆç°¡ç•¥åŒ–ï¼‰
                axis_result["confidence"] = max(confidence, 0.6)
        except:
            # JSONãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            axis_result = {
                "axis_name": axis_name,
                "integrated_conclusion": f"{axis_name}ã«é–¢ã™ã‚‹åŸºæœ¬çš„ãªåˆ†æçµæœ",
                "confidence": 0.5,
                "reasoning_chain": [f"{axis_name}ã®åˆ†æã‚’å®Ÿè¡Œ"]
            }
        
        return axis_result
    
    async def _verify_and_improve(self, reasoning_results: Dict[str, Any]) -> Dict[str, Any]:
        """æ¤œè¨¼ãƒ»æ”¹å–„ãƒ•ã‚§ãƒ¼ã‚º"""
        self.current_step_id += 1
        
        # çµæœã®ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
        axis_results = reasoning_results.get("axis_results", [])
        confidence_scores = reasoning_results.get("confidence_scores", [])
        
        verification_prompt = f"""ä»¥ä¸‹ã®åˆ†æçµæœã®ä¸€è²«æ€§ã¨å“è³ªã‚’æ¤œè¨¼ã—ã¦ãã ã•ã„ï¼š

åˆ†æçµæœ:
{json.dumps(axis_results, ensure_ascii=False, indent=2)}

æ¤œè¨¼é …ç›®:
1. å„è»¸ã®çµè«–é–“ã«çŸ›ç›¾ã¯ãªã„ã‹ï¼Ÿ
2. ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã¯é©åˆ‡ã‹ï¼Ÿ
3. è¿½åŠ ã§å¿…è¦ãªåˆ†æã¯ã‚ã‚‹ã‹ï¼Ÿ
4. çµè«–ã®æ ¹æ‹ ã¯ååˆ†ã‹ï¼Ÿ

æ¤œè¨¼çµæœã‚’JSONå½¢å¼ã§ï¼š
{{
    "consistency_score": 0.8,
    "contradictions_found": [],
    "quality_issues": [],
    "improvement_suggestions": [],
    "verified_conclusions": {{}},
    "overall_confidence": 0.8
}}
"""
        
        verification_response = await self.generate_content_async(
            verification_prompt,
            agent_name="æ¤œè¨¼ã‚¨ãƒ³ã‚¸ãƒ³"
        )
        
        try:
            verification_results = json.loads(verification_response.strip())
        except:
            verification_results = {
                "consistency_score": 0.7,
                "overall_confidence": sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0.5
            }
        
        # æ€è€ƒã‚¹ãƒ†ãƒƒãƒ—è¨˜éŒ²
        step = ThinkingStep(
            step_id=self.current_step_id,
            phase="verification",
            input_data=json.dumps(reasoning_results, ensure_ascii=False),
            output_data=json.dumps(verification_results, ensure_ascii=False),
            confidence=verification_results.get("overall_confidence", 0.5)
        )
        self.steps_log.append(step)
        
        return {
            "reasoning_results": reasoning_results,
            "verification_results": verification_results,
            "sources": ["æ·±å±¤æ¨è«–åˆ†æ", "å¤šæ®µéšæ¤œè¨¼"]
        }
    
    async def _synthesize_final_answer(self, verified_result: Dict[str, Any]) -> Dict[str, Any]:
        """æœ€çµ‚å›ç­”çµ±åˆ"""
        self.current_step_id += 1
        
        axis_results = verified_result["reasoning_results"].get("axis_results", [])
        verification = verified_result["verification_results"]
        
        synthesis_prompt = f"""ä»¥ä¸‹ã®æ¤œè¨¼æ¸ˆã¿åˆ†æçµæœã‹ã‚‰æœ€çµ‚çš„ãªå›ç­”ã‚’çµ±åˆã—ã¦ãã ã•ã„ï¼š

åˆ†æçµæœ:
{json.dumps(axis_results, ensure_ascii=False, indent=2)}

æ¤œè¨¼çµæœ:
{json.dumps(verification, ensure_ascii=False, indent=2)}

è¦æ±‚:
1. å„è»¸ã®çµè«–ã‚’çµ±åˆã—ãŸåŒ…æ‹¬çš„å›ç­”
2. ä¿¡é ¼åº¦ã®é«˜ã„æƒ…å ±ã‚’å„ªå…ˆ
3. çŸ›ç›¾ç‚¹ã¯æ˜è¨˜
4. 300-500æ–‡å­—ã§ç°¡æ½”ã«

å›ç­”ã‚’JSONå½¢å¼ã§ï¼š
{{
    "answer": "çµ±åˆã•ã‚ŒãŸæœ€çµ‚å›ç­”",
    "confidence": 0.8,
    "key_points": ["è¦ç‚¹1", "è¦ç‚¹2"],
    "limitations": ["åˆ¶é™äº‹é …1"],
    "synthesis_reasoning": ["çµ±åˆç†ç”±1", "çµ±åˆç†ç”±2"]
}}
"""
        
        final_response = await self.generate_content_async(
            synthesis_prompt,
            agent_name="çµ±åˆã‚¨ãƒ³ã‚¸ãƒ³"
        )
        
        try:
            final_answer = json.loads(final_response.strip())
        except:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å›ç­”
            conclusions = [result.get("integrated_conclusion", "") for result in axis_results]
            final_answer = {
                "answer": " ".join(conclusions),
                "confidence": verification.get("overall_confidence", 0.5),
                "key_points": ["çµ±åˆåˆ†æçµæœ"],
                "limitations": ["JSONè§£æã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ"]
            }
        
        # æœ€çµ‚æ€è€ƒã‚¹ãƒ†ãƒƒãƒ—è¨˜éŒ²
        step = ThinkingStep(
            step_id=self.current_step_id,
            phase="synthesis",
            input_data=json.dumps(verified_result, ensure_ascii=False),
            output_data=json.dumps(final_answer, ensure_ascii=False),
            confidence=final_answer.get("confidence", 0.5)
        )
        self.steps_log.append(step)
        
        return final_answer
    
    def _calculate_quality_metrics(self) -> Dict[str, float]:
        """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—"""
        if not self.steps_log:
            return {}
        
        # å„ãƒ•ã‚§ãƒ¼ã‚ºã®ä¿¡é ¼åº¦å¹³å‡
        phase_confidences = {}
        for step in self.steps_log:
            phase = step.phase
            if phase not in phase_confidences:
                phase_confidences[phase] = []
            phase_confidences[phase].append(step.confidence)
        
        metrics = {}
        for phase, confidences in phase_confidences.items():
            metrics[f"{phase}_confidence"] = sum(confidences) / len(confidences)
        
        # å…¨ä½“å“è³ªã‚¹ã‚³ã‚¢
        all_confidences = [step.confidence for step in self.steps_log]
        metrics["overall_quality"] = sum(all_confidences) / len(all_confidences)
        metrics["step_count"] = len(self.steps_log)
        metrics["complexity_score"] = min(len(self.steps_log) / 5.0, 1.0)  # æœ€å¤§1.0
        
        return metrics
    
    def get_thinking_visualization(self) -> Dict[str, Any]:
        """æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã®å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
        return {
            "steps": [
                {
                    "id": step.step_id,
                    "phase": step.phase,
                    "confidence": step.confidence,
                    "timestamp": step.timestamp.isoformat(),
                    "reasoning_chain": step.reasoning_chain
                }
                for step in self.steps_log
            ],
            "phase_summary": self._get_phase_summary(),
            "confidence_trend": [step.confidence for step in self.steps_log]
        }
    
    def _get_phase_summary(self) -> Dict[str, int]:
        """ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥ã‚¹ãƒ†ãƒƒãƒ—æ•°ã®è¦ç´„"""
        phase_counts = {}
        for step in self.steps_log:
            phase = step.phase
            phase_counts[phase] = phase_counts.get(phase, 0) + 1
        return phase_counts 